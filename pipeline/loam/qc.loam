import binaries._
import config._
import scripts._
import store_helpers._

import loamstream.conf.DataConfig
import loamstream.googlecloud.HailSupport._
import loamstream.model.Store
import loamstream.util.CanBeClosed.enclosed

val nChr = endChr - startChr + 1
val kgSampleId = dataConfig.getStr("kgSampleId")
val kgSamplePop = dataConfig.getStr("kgSamplePop")
val kgSampleGroup = dataConfig.getStr("kgSampleGroup")
val kgVcfBaseWild = dataConfig.getStr("kgVcfBaseWild")
val kgLegendWild = dataConfig.getStr("kgLegendWild")
val humanReferenceWild = dataConfig.getStr("humanReferenceWild")
val phenoFile = dataConfig.getStr("pheno")
val phenoId = dataConfig.getStr("phenoId")
val phenoSrSex = dataConfig.getStr("phenoSrSex")
val phenoSrRace = dataConfig.getStr("phenoSrRace")
val phenoStatus = dataConfig.getStr("phenoStatus")
val nArrays = dataConfig.getObjList("arrays").size
val nMetrics = sampleQcMetrics.size
val qcReportAuthors = dataConfig.getStrList("qcReportAuthors").mkString(",")
val analysisReportAuthors = dataConfig.getStrList("analysisReportAuthors").mkString(",")
val analysisReportAcknowledgements = dataConfig.getStrList("analysisReportAcknowledgements").mkString(",")

// generate list of tuples that define each model
var modelSeq: Seq[(String, String, String, String, String, String, Int)] = Seq()
val phases = dataConfig.getObjList("phases")
for { i <- 0 until phases.size } 
  {
    for { j <- 0 until phases(i).getObjList("phenotypes").size }
      {
        for { test <- phases(i).getObjList("phenotypes")(j).getStrList("tests") }
          {
            for { covars <- phases(i).getObjList("phenotypes")(j).getStrList("covars") }
              {
                modelSeq = modelSeq :+ (
                  (phases(i).getObjList("phenotypes")(j).getStr("phenoName"),
                    phases(i).getObjList("phenotypes")(j).getStr("trans"),
                    test,
                    covars,
                    phases(i).getStr("strat"),
                    phases(i).getObjList("phenotypes")(j).getStr("ancestryKeep"),
                    i + 1)
                  )
              }
          }
      }
  }

// generate list of tuples that define each known loci table
var knownLociSeq: Seq[(String, String, String, String, String, String, String, String, Int, Int, Int)] = Seq()
for { i <- 0 until phases.size } 
  {
    for { j <- 0 until phases(i).getObjList("phenotypes").size }
      {
        for { k <- 0 until phases(i).getObjList("phenotypes")(j).getObjList("knownLoci").size }
          {
            knownLociSeq = knownLociSeq :+ (
              (phases(i).getObjList("phenotypes")(j).getStr("phenoName"),
                phases(i).getObjList("phenotypes")(j).getStr("trans"),
                phases(i).getObjList("phenotypes")(j).getObjList("knownLoci")(k).getStr("test"),
                phases(i).getObjList("phenotypes")(j).getObjList("knownLoci")(k).getStr("covars"),
                phases(i).getStr("strat"),
                phases(i).getObjList("phenotypes")(j).getObjList("knownLoci")(k).getStr("pop"),
                phases(i).getObjList("phenotypes")(j).getObjList("knownLoci")(k).getStr("hiLd"),
                phases(i).getObjList("phenotypes")(j).getObjList("knownLoci")(k).getStr("data"),
                i + 1,
                j + 1,
                k + 1)
              )  
          }
      }
  }

object Input {

  object Local {
    val kgSample = store.at(path(dataConfig.getStr("kgSample"))).asInput
    val pheno = store.at(path(phenoFile)).asInput
    val genes = store.at(path(dataConfig.getStr("genePositions"))).asInput
  }

  object Google {
    val kgPurcellVcf = store.at(uri(dataConfig.getStr("kgPurcellVcfGoogle"))).asInput
    val kgSample = store.at(uri(dataConfig.getStr("kgSampleGoogle"))).asInput
    val regionsExclude = store.at(uri(dataConfig.getStr("regionsExcludeGoogle"))).asInput
    val pheno = store.at(googleOutDir / s"${phenoFile}".split("/").last)
  }

}

object Params {

  final case class Chr(
    rawChrName: Path,
    rawChr: Seq[Store],
    harmKgChrName: Path,
    harmKgHuRefChrName: Path,
    harmKgChr: Seq[Store],
    harmKgHuRefChr: Seq[Store],
    kgVcfChr: Store,
    kgLegendChr: Store,
    humanReference: Store,
    harmNonKgChrRemove: Store,
    harmNonKgChrIgnore: Store,
    harmNonKgChrMono: Store,
    harmNonKgChrNomatch: Store,
    harmNonKgChrFlip: Store,
    harmNonKgChrForceA1: Store,
    harmKgChrVarIdUpdate: Store,
    harmKgChrVarSnpLog: Store,
    harmMergeLine: String)
  
  final case class Metric(
    sampleqcStatsAdjIndMetric: String,
    sampleqcStatsAdjIndClusterName: Path,
    sampleqcStatsAdjIndClusterFet: Store,
    sampleqcStatsAdjIndClusterClu: Store,
    sampleqcStatsAdjIndClusterKlg: Store,
    sampleqcStatsAdjIndClusterKlustakwikLog: Store)
  
  final case class Model(
    modelPheno: String,
    modelTest: String,
    modelCovars: String,
    modelTrans: String,
    modelStrat: String,
    modelAncestryKeep: String,
    modelPhase: Int,
    modelPhenoPrelimFile: Store,
    modelPhenoPrelimFileCloud: Store,
    modelSamplesInclude: Store,
    modelSamplesIncludeCloud: Store,
    modelPhenoFileLog: Store,
    modelPhenoFile: Store,
    modelPcsFile: Store,
    modelPhenoFileCloud: Store,
    modelPcsFileCloud: Store,
    modelResults: Store,
    modelResultsTbi: Store,
    modelResultsCloud: Store)
  
  final case class Result(
    resultPheno: String,
    resultTest: String,
    resultCovars: String,
    resultTrans: String,
    resultStrat: String,
    resultFinal: Store,
    resultFinalTop1000: Store,
    resultFinalTop1000Genes: Store,
    resultFinalTop20AnnotAlignedRisk: Store,
    resultFinalTopLoci: Store,
    resultFinalTopLociReport: Store,
    resultFinalTopLociReportHighlighted: Store,
    resultFinalTbi: Store,
    resultFinalCloud: Store,
    resultFinalQqPlot: Store,
    resultFinalMhtPlot: Store,
    resultFinalSigRegions: Store,
    resultFinalRegplotBase: String,
    resultFinalRegplotName: Path)

  final case class KnownLoci(
    knownLociPhenoName: String,
    knownLociTrans: String,
    knownLociTest: String,
    knownLociCovars: String,
    knownLociStrat: String,
    knownLociPop: String,
    knownLociHiLd: Store,
    knownLociHiLdCloud: Store,
    knownLociPhase: Int,
    knownLociPhenoPrelimFile: Store,
    knownLociPhenoPrelimFileCloud: Store,
    knownLociSamplesInclude: Store,
    knownLociSamplesIncludeCloud: Store,
    knownLociPhenoFileLog: Store,
    knownLociPhenoFile: Store,
    knownLociPcsFile: Store,
    knownLociPhenoFileCloud: Store,
    knownLociPcsFileCloud: Store,
    knownLociResults: Store,
    knownLociResultsCloud: Store)

  final case class ResultKnownLoci(
    resultKnownLociPhenoName: String,
    resultKnownLociTrans: String,
    resultKnownLociTest: String,
    resultKnownLociCovars: String,
    resultKnownLociStrat: String,
    resultKnownLociPop: String,
    resultKnownLociHiLd: Store,
    resultKnownLociData: Store,
    resultKnownLociN: String,
    resultKnownLociCase: String,
    resultKnownLociCtrl: String,
    resultKnownLociDesc: String,
    resultKnownLociTag: String,
    resultKnownLociCitation: String,
    resultKnownLociPhase: Int,
    resultKnownLociPhenoNum: Int,
    resultKnownLociKnownLociNum: Int,
    resultKnownLociFinal: Store,
    resultKnownLociFinalCloud: Store,
    resultKnownLociFinalTop50Known: Store)

  final case class Arr(
    arrayId: String,
    arrayDataPath: String,
    arrayDataType: String,
    arrayData: Store,
    arrayDataRawName: Path,
    arrayDataRawUnplaced: Store,
    arrayDataRawUnique: Store,
    arrayDataRawIndel: Store,
    arrayDataRawLmiss: Store,
    arrayDataRawFreq: Store,
    arrayDataRawMono: Store,
    arrayDataRawDupRemove: Store,
    arrayDataPreparedName: Path,
    arrayDataPrepared: Seq[Store],
    arrayDataPreparedMultiallelic: Store,
    harmName: Path,
    harm: Seq[Store],
    harmNonKgRemove: Store,
    harmNonKgIgnore: Store,
    harmNonKgMono: Store,
    harmNonKgNomatch: Store,
    harmNonKgFlip: Store,
    harmNonKgForceA1: Store,
    harmKgVarSnpLog: Store,
    harmRefName: Path,
    harmRef: Seq[Store],
    harmRefVcf: Store,
    harmRefVcfCloud: Store,
    harmRefVcfTbi: Store,
    harmRefVcfTbiCloud: Store,
    harmRefVdsCloud: Store,
    harmRefFiltNameCloud: URI,
    harmRefFiltCloud: Seq[Store],
    harmRefFiltVdsCloud: Store,
    harmRefFiltVariantQcCloud: Store,
    harmRefFiltVariantsPrunedInCloud: Store,
    harmRefFiltPrunedName: Path,
    harmRefFiltPruned: Seq[Store],
    harmRefFiltPrunedNameCloud: URI,
    harmRefFiltPrunedCloud: Seq[Store],
    harmRefFiltPrunedVdsCloud: Store,
    paramsByArrByChr: Seq[(Int, Chr)],
    paramsByArrByModel: Seq[(Int, Model)],
    paramsByArrByKnownLoci: Seq[(Int, KnownLoci)],
    paramsByArrByMetric: Seq[(Int, Metric)],
    paramsByArrByChrSorted: Seq[Chr],
    paramsByArrByModelSorted: Seq[Model],
    paramsByArrByKnownLociSorted: Seq[KnownLoci],
    paramsByArrByMetricSorted: Seq[Metric],
    harmMergeLines: Seq[String],
    harmMergeList: Store,
    sampleqcStatsAdjIndClusterCluList: Seq[String],
    harmForceA2: Store,
    kinName: Path,
    kinLog: Store,
    kinTmpDat: Store,
    kinTmpPed: Store,
    kinKin: Store,
    kinKin0: Store,
    kinKin0Related: Store,
    kinFamsizes: Store,
    ancestryPcaName: Path,
    harmRef1kgName: Path,
    harmRef1kg: Seq[Store],
    harmRef1kgGds: Store,
    ancestryPcaLog: Store,
    ancestryPcaScores: Store,
    ancestryPcaScoresPlots: Store,
    ancestryPcaScoresPlotPc1VsPc2: Store,
    ancestryPcaScoresPlotPc2VsPc3: Store,
    harmRef1kgNameCloud: URI,
    harmRef1kgCloud: Seq[Store],
    ancestryClusterName: Path,
    ancestryClusterLog: Store,
    ancestryClusterFet: Store,
    ancestryClusterClu: Store,
    ancestryClusterKlg: Store,
    ancestryClusterPlots: Store,
    ancestryClusterPlotPc1VsPc2: Store,
    ancestryClusterPlotPc2VsPc3: Store,
    ancestryClusterPlotsCenters: Store,
    ancestryClusterPlotsNo1kg: Store,
    ancestryClusterXtabs: Store,
    ancestryClusterGroups: Store,
    ancestryInferred: Store,
    harmRefFiltPrunedPcaGds: Store,
    pcaLog: Store,
    pcaScores: Store,
    sampleqcStats: Store,
    sampleqcStatsAdj: Store,
    sampleqcStatsAdjCorrPlots: Store,
    sampleqcStatsAdjPcaLoadings: Store,
    sampleqcStatsAdjPcaScoresPlots: Store,
    sampleqcStatsAdjPcaScores: Store,
    sampleqcSexcheck: Store,
    sampleqcSexcheckProblems: Store,
    sampleqcSexcheckCloud: Store,
    sampleqcSexcheckProblemsCloud: Store,
    sampleqcStatsCloud: Store,
    sampleqcStatsAdjClusterFet: Store,
    sampleqcStatsAdjClusterClu: Store,
    sampleqcStatsAdjClusterKlg: Store,
    sampleqcStatsAdjClusterKlustakwikLog: Store,
    sampleqcStatsAdjClusterOutliers: Store,
    sampleqcStatsAdjClusterPlots: Store,
    sampleqcStatsAdjClusterXtabs: Store,
    sampleqcStatsAdjClusterName: Path,
    sampleqcStatsAdjIndBoxplots: Store,
    sampleqcStatsAdjIndDiscreteness: Store,
    sampleqcStatsAdjOutliersTable: Store,
    sampleqcOutlierPlotPdf: Store,
    sampleqcOutlierPlotPng: Store,
    sampleqcStatsAdjStripchart: Store,
    finalSampleExclusions: Store,
    finalSampleExclusionsCloud: Store,
    variantqcStats: Store,
    variantqcStatsCloud: Store,
    finalVariantExclusions: Store,
    finalVariantExclusionsCloud: Store,
    cleanName: Path,
    clean: Seq[Store],
    cleanGds: Store,
    cleanPcaScores: Store,
    cleanPcaLog: Store,
    cleanNameCloud: URI,
    cleanCloud: Seq[Store],
    cleanVcf: Store,
    cleanVcfCloud: Store,
    cleanVcfTbi: Store,
    cleanVdsCloud: Store)

  val paramsByResult: Seq[(Int, Result)] = (0 until modelSeq.size).map { result =>
  
    val resultPheno = modelSeq(result)._1
    val resultTrans = modelSeq(result)._2
    val resultTest = modelSeq(result)._3
    val resultCovars = modelSeq(result)._4
    val resultStrat = modelSeq(result)._5
  
    val covarsString = resultCovars.replace("+","_")
    val resultFinalRegplotBase = s"${projectId}.assoc.$resultPheno.$resultTrans.$covarsString.$resultTest.regplot"
  
    result -> Result(
      resultPheno = resultPheno,
      resultTest = resultTest,
      resultCovars = resultCovars,
      resultTrans = resultTrans,
      resultStrat = resultStrat,
      resultFinal = store.at(localOutDir / s"${projectId}.assoc.$resultPheno.$resultTrans.$covarsString.$resultTest.results.tsv.bgz"),
      resultFinalTbi = store.at(localOutDir / s"${projectId}.assoc.$resultPheno.$resultTrans.$covarsString.$resultTest.results.tsv.bgz.tbi"),
      resultFinalTop1000 = store.at(localOutDir / s"${projectId}.assoc.$resultPheno.$resultTrans.$covarsString.$resultTest.results.top1000.tsv"),
      resultFinalTop1000Genes = store.at(localOutDir / s"${projectId}.assoc.$resultPheno.$resultTrans.$covarsString.$resultTest.results.top1000.genes.tsv"),
      resultFinalTop20AnnotAlignedRisk = store.at(localOutDir / s"${projectId}.assoc.$resultPheno.$resultTrans.$covarsString.$resultTest.results.top20.annot.aligned_risk.tsv"),
      resultFinalTopLoci = store.at(localOutDir / s"${projectId}.assoc.$resultPheno.$resultTrans.$covarsString.$resultTest.results.toploci.tsv"),
      resultFinalTopLociReport = store.at(localOutDir / s"${projectId}.assoc.$resultPheno.$resultTrans.$covarsString.$resultTest.results.toploci.report.tsv"),
      resultFinalTopLociReportHighlighted = store.at(localOutDir / s"${projectId}.assoc.$resultPheno.$resultTrans.$covarsString.$resultTest.results.toploci.report.highlighted.tsv"),
      resultFinalCloud = store.at(googleOutDir / s"${projectId}.assoc.$resultPheno.$resultTrans.$covarsString.$resultTest.results.tsv.bgz"),
      resultFinalQqPlot = store.at(localOutDir / s"${projectId}.assoc.$resultPheno.$resultTrans.$covarsString.$resultTest.qq.png"),
      resultFinalMhtPlot = store.at(localOutDir / s"${projectId}.assoc.$resultPheno.$resultTrans.$covarsString.$resultTest.mht.png"),
      resultFinalSigRegions = store.at(localOutDir / s"${projectId}.assoc.$resultPheno.$resultTrans.$covarsString.$resultTest.sigregions.tsv"),
      resultFinalRegplotBase = resultFinalRegplotBase,
      resultFinalRegplotName = localOutDir / resultFinalRegplotBase)
  
  }
  
  val paramsByResultKnownLoci: Seq[(Int, ResultKnownLoci)] = (0 until knownLociSeq.size).map { resultKnownLoci =>

    val resultKnownLociPhenoName = knownLociSeq(resultKnownLoci)._1
    val resultKnownLociTrans = knownLociSeq(resultKnownLoci)._2
    val resultKnownLociTest = knownLociSeq(resultKnownLoci)._3
    val resultKnownLociCovars = knownLociSeq(resultKnownLoci)._4
    val resultKnownLociStrat = knownLociSeq(resultKnownLoci)._5
    val resultKnownLociPop = knownLociSeq(resultKnownLoci)._6
    val resultKnownLociHiLdString = knownLociSeq(resultKnownLoci)._7
    val resultKnownLociDataString = knownLociSeq(resultKnownLoci)._8
    val resultKnownLociPhase = knownLociSeq(resultKnownLoci)._9
    val resultKnownLociPhenoNum = knownLociSeq(resultKnownLoci)._10
    val resultKnownLociKnownLociNum = knownLociSeq(resultKnownLoci)._11

    val knownLociCovarsString = resultKnownLociCovars.replace("+","_")

    resultKnownLoci -> ResultKnownLoci(
      resultKnownLociPhenoName = resultKnownLociPhenoName,
      resultKnownLociTrans = resultKnownLociTrans,
      resultKnownLociTest = resultKnownLociTest,
      resultKnownLociCovars = resultKnownLociCovars,
      resultKnownLociStrat = resultKnownLociStrat,
      resultKnownLociPop = resultKnownLociPop,
      resultKnownLociHiLd = store.at(path(resultKnownLociHiLdString)).asInput,
      resultKnownLociData = store.at(path(resultKnownLociDataString)).asInput,
      resultKnownLociN = if (dataConfig.getObjList("phases")(resultKnownLociPhase - 1).getObjList("phenotypes")(resultKnownLociPhenoNum - 1).getObjList("knownLoci")(resultKnownLociKnownLociNum - 1).isDefined("n")) { dataConfig.getObjList("phases")(resultKnownLociPhase - 1).getObjList("phenotypes")(resultKnownLociPhenoNum - 1).getObjList("knownLoci")(resultKnownLociKnownLociNum - 1).getStr("n") } else { "" },
      resultKnownLociCase = if (dataConfig.getObjList("phases")(resultKnownLociPhase - 1).getObjList("phenotypes")(resultKnownLociPhenoNum - 1).getObjList("knownLoci")(resultKnownLociKnownLociNum - 1).isDefined("nCase")) { dataConfig.getObjList("phases")(resultKnownLociPhase - 1).getObjList("phenotypes")(resultKnownLociPhenoNum - 1).getObjList("knownLoci")(resultKnownLociKnownLociNum - 1).getStr("nCase") } else { "" },
      resultKnownLociCtrl = if (dataConfig.getObjList("phases")(resultKnownLociPhase - 1).getObjList("phenotypes")(resultKnownLociPhenoNum - 1).getObjList("knownLoci")(resultKnownLociKnownLociNum - 1).isDefined("nCtrl")) { dataConfig.getObjList("phases")(resultKnownLociPhase - 1).getObjList("phenotypes")(resultKnownLociPhenoNum - 1).getObjList("knownLoci")(resultKnownLociKnownLociNum - 1).getStr("nCtrl") } else { "" },
      resultKnownLociDesc = dataConfig.getObjList("phases")(resultKnownLociPhase - 1).getObjList("phenotypes")(resultKnownLociPhenoNum - 1).getObjList("knownLoci")(resultKnownLociKnownLociNum - 1).getStr("desc"),
      resultKnownLociTag = dataConfig.getObjList("phases")(resultKnownLociPhase - 1).getObjList("phenotypes")(resultKnownLociPhenoNum - 1).getObjList("knownLoci")(resultKnownLociKnownLociNum - 1).getStr("tag"),
      resultKnownLociCitation = dataConfig.getObjList("phases")(resultKnownLociPhase - 1).getObjList("phenotypes")(resultKnownLociPhenoNum - 1).getObjList("knownLoci")(resultKnownLociKnownLociNum - 1).getStr("citation"),
      resultKnownLociPhase = resultKnownLociPhase,
      resultKnownLociPhenoNum = resultKnownLociPhenoNum,
      resultKnownLociKnownLociNum = resultKnownLociKnownLociNum,
      resultKnownLociFinal = store.at(localOutDir / s"${projectId}.assoc.$resultKnownLociPhenoName.$resultKnownLociTrans.$knownLociCovarsString.$resultKnownLociTest.results.known_loci.tsv"),
      resultKnownLociFinalCloud = store.at(googleOutDir / s"${projectId}.assoc.$resultKnownLociPhenoName.$resultKnownLociTrans.$knownLociCovarsString.$resultKnownLociTest.results.known_loci.tsv"),
      resultKnownLociFinalTop50Known = store.at(localOutDir / s"${projectId}.assoc.$resultKnownLociPhenoName.$resultKnownLociTrans.$knownLociCovarsString.$resultKnownLociTest.results.known_loci.top50.tsv"))

  }

  val paramsByArr: Seq[(Int, Arr)] = (0 until nArrays).map { arr =>
  
    val arrayId = dataConfig.getObjList("arrays")(arr).getStr("arrayId")
    val arrayDataPath = dataConfig.getObjList("arrays")(arr).getStr("dataPath")
    val arrayDataType = dataConfig.getObjList("arrays")(arr).getStr("dataType")
    val arrayData = {
      if (arrayDataType == "vcf") { store.at(path(arrayDataPath)).asInput }
      else { store.at(path(s"${arrayDataPath}.bed")).asInput }
    }
    val arrayDataRawBase = s"${projectId}.${arrayId}"
    val arrayDataRawName = localOutDir / s"${arrayDataRawBase}.raw"
    val arrayDataPreparedName = localOutDir / s"${arrayDataRawBase}.prepared"
  
    val paramsByArrByChr = (startChr to endChr).map { chr =>
    
      val rawChrBase = s"${projectId}.${arrayId}.chr$chr"
      val harmKgChrBase = s"${rawChrBase}.harmkg"
      val harmKgChrName = localOutDir / harmKgChrBase
      val harmKgHuRefChrName = localOutDir / s"${harmKgChrBase}.huref"
      val rawChrName = localOutDir / rawChrBase
      val kgVcfChr = store.at(
          kgVcfBaseWild
            .replace("[CHROMOSOME]", s"$chr")
            .replace("23.phase3_shapeit2_mvncall_integrated_v5a",
                     "X.phase3_shapeit2_mvncall_integrated_v1b") + ".vcf.gz").asInput
      val kgLegendChr = store.at(
          kgLegendWild
            .replace("[CHROMOSOME]", s"$chr")
            .replace("23",
                     "X")).asInput
      val humanReference = store.at(
          humanReferenceWild
            .replace("[CHROMOSOME]", s"$chr")
            .replace("23",
                     "X")).asInput
    
      chr -> Chr(
        rawChrName = rawChrName,
        rawChr = bedBimFam(rawChrName),
        harmKgChrName = harmKgChrName,
        harmKgHuRefChrName = harmKgHuRefChrName,
        harmKgChr = bedBimFam(harmKgChrName),
        harmKgHuRefChr = bedBimFam(harmKgHuRefChrName),
        kgVcfChr = kgVcfChr,
        kgLegendChr = kgLegendChr,
        humanReference = humanReference,
        harmNonKgChrRemove = store.at(localOutDir / s"${harmKgChrBase}.nonkg.remove"),
        harmNonKgChrIgnore = store.at(localOutDir / s"${harmKgChrBase}.nonkg.ignore"),
        harmNonKgChrMono = store.at(localOutDir / s"${harmKgChrBase}.nonkg.mono"),
        harmNonKgChrNomatch = store.at(localOutDir / s"${harmKgChrBase}.nonkg.nomatch"),
        harmNonKgChrFlip = store.at(localOutDir / s"${harmKgChrBase}.nonkg.flip"),
        harmNonKgChrForceA1 = store.at(localOutDir / s"${harmKgChrBase}.nonkg.force_a1"),
        harmKgChrVarIdUpdate = store.at(localOutDir / s"${harmKgChrBase}_idUpdates.txt"),
        harmKgChrVarSnpLog = store.at(localOutDir / s"${harmKgChrBase}_snpLog.log"),
        harmMergeLine = s"${localOutDir}/${harmKgChrBase}")
    }
    
    val paramsByArrByModel = (0 until modelSeq.size).map { model =>
    
      val modelPheno = modelSeq(model)._1
      val modelTrans = modelSeq(model)._2
      val modelTest = modelSeq(model)._3
      val modelCovars = modelSeq(model)._4
      val modelStrat = modelSeq(model)._5
      val modelAncestryKeep = modelSeq(model)._6
      val modelPhase = modelSeq(model)._7
    
      val modelCovarsString = modelCovars.replace("+","_")
    
      model -> Model(
        modelPheno = modelPheno,
        modelTest = modelTest,
        modelCovars = modelCovars,
        modelTrans = modelTrans,
        modelStrat = modelStrat,
        modelPhase = modelPhase,
        modelAncestryKeep = modelAncestryKeep,
        modelPhenoPrelimFile = store.at(localOutDir / s"${projectId}.${arrayId}.assoc.$modelPheno.$modelTrans.$modelCovarsString.$modelTest.prelim_pheno.tsv"),
        modelPhenoPrelimFileCloud = store.at(googleOutDir / s"${projectId}.${arrayId}.assoc.$modelPheno.$modelTrans.$modelCovarsString.$modelTest.prelim_pheno.tsv"),
        modelSamplesInclude = store.at(localOutDir / s"${projectId}.${arrayId}.assoc.$modelPheno.$modelTrans.$modelCovarsString.$modelTest.samples.include"),
        modelSamplesIncludeCloud = store.at(googleOutDir / s"${projectId}.${arrayId}.assoc.$modelPheno.$modelTrans.$modelCovarsString.$modelTest.samples.include"),
        modelPhenoFileLog = store.at(localOutDir / s"${projectId}.${arrayId}.assoc.$modelPheno.$modelTrans.$modelCovarsString.$modelTest.pheno.log"),
        modelPhenoFile = store.at(localOutDir / s"${projectId}.${arrayId}.assoc.$modelPheno.$modelTrans.$modelCovarsString.$modelTest.pheno.tsv"),
        modelPcsFile = store.at(localOutDir / s"${projectId}.${arrayId}.assoc.$modelPheno.$modelTrans.$modelCovarsString.$modelTest.pcs.include"),
        modelPhenoFileCloud = store.at(googleOutDir / s"${projectId}.${arrayId}.assoc.$modelPheno.$modelTrans.$modelCovarsString.$modelTest.pheno.tsv"),
        modelPcsFileCloud = store.at(googleOutDir / s"${projectId}.${arrayId}.assoc.$modelPheno.$modelTrans.$modelCovarsString.$modelTest.pcs.include"),
        modelResults = store.at(localOutDir / s"${projectId}.${arrayId}.assoc.$modelPheno.$modelTrans.$modelCovarsString.$modelTest.results.tsv.bgz"),
        modelResultsTbi = store.at(localOutDir / s"${projectId}.${arrayId}.assoc.$modelPheno.$modelTrans.$modelCovarsString.$modelTest.results.tsv.bgz.tbi"),
        modelResultsCloud = store.at(googleOutDir / s"${projectId}.${arrayId}.assoc.$modelPheno.$modelTrans.$modelCovarsString.$modelTest.results.tsv.bgz"))
    
    }

    val paramsByArrByKnownLoci = (0 until knownLociSeq.size).map { knownLoci =>

      val knownLociPhenoName = knownLociSeq(knownLoci)._1
      val knownLociTrans = knownLociSeq(knownLoci)._2
      val knownLociTest = knownLociSeq(knownLoci)._3
      val knownLociCovars = knownLociSeq(knownLoci)._4
      val knownLociStrat = knownLociSeq(knownLoci)._5
      val knownLociPop = knownLociSeq(knownLoci)._6
      val knownLociHiLdString = knownLociSeq(knownLoci)._7
      val knownLociPhase = knownLociSeq(knownLoci)._9

      val knownLociCovarsString = knownLociCovars.replace("+","_")
      val knownLociHiLdStringBase = knownLociHiLdString.split("/").last
    
      knownLoci -> KnownLoci(
        knownLociPhenoName = knownLociPhenoName,
        knownLociTrans = knownLociTrans,
        knownLociTest = knownLociTest,
        knownLociCovars = knownLociCovars,
        knownLociStrat = knownLociStrat,
        knownLociPop = knownLociPop,
        knownLociHiLd = store.at(path(knownLociHiLdString)).asInput,
        knownLociHiLdCloud = store.at(googleOutDir / s"${projectId}.${arrayId}.assoc.$knownLociPhenoName.$knownLociTrans.$knownLociCovarsString.$knownLociTest.known_loci.${knownLociHiLdStringBase}"),
        knownLociPhase = knownLociPhase,
        knownLociPhenoPrelimFile = store.at(localOutDir / s"${projectId}.${arrayId}.assoc.$knownLociPhenoName.$knownLociTrans.$knownLociCovarsString.$knownLociTest.known_loci.prelim_pheno.tsv"),
        knownLociPhenoPrelimFileCloud = store.at(googleOutDir / s"${projectId}.${arrayId}.assoc.$knownLociPhenoName.$knownLociTrans.$knownLociCovarsString.$knownLociTest.known_loci.prelim_pheno.tsv"),
        knownLociSamplesInclude = store.at(localOutDir / s"${projectId}.${arrayId}.assoc.$knownLociPhenoName.$knownLociTrans.$knownLociCovarsString.$knownLociTest.known_loci.samples.include"),
        knownLociSamplesIncludeCloud = store.at(googleOutDir / s"${projectId}.${arrayId}.assoc.$knownLociPhenoName.$knownLociTrans.$knownLociCovarsString.$knownLociTest.known_loci.samples.include"),
        knownLociPhenoFileLog = store.at(localOutDir / s"${projectId}.${arrayId}.assoc.$knownLociPhenoName.$knownLociTrans.$knownLociCovarsString.$knownLociTest.known_loci.pheno.log"),
        knownLociPhenoFile = store.at(localOutDir / s"${projectId}.${arrayId}.assoc.$knownLociPhenoName.$knownLociTrans.$knownLociCovarsString.$knownLociTest.known_loci.pheno.tsv"),
        knownLociPcsFile = store.at(localOutDir / s"${projectId}.${arrayId}.assoc.$knownLociPhenoName.$knownLociTrans.$knownLociCovarsString.$knownLociTest.known_loci.pcs.include"),
        knownLociPhenoFileCloud = store.at(googleOutDir / s"${projectId}.${arrayId}.assoc.$knownLociPhenoName.$knownLociTrans.$knownLociCovarsString.$knownLociTest.known_loci.pheno.tsv"),
        knownLociPcsFileCloud = store.at(googleOutDir / s"${projectId}.${arrayId}.assoc.$knownLociPhenoName.$knownLociTrans.$knownLociCovarsString.$knownLociTest.known_loci.pcs.include"),
        knownLociResults = store.at(localOutDir / s"${projectId}.${arrayId}.assoc.$knownLociPhenoName.$knownLociTrans.$knownLociCovarsString.$knownLociTest.known_loci.results.tsv"),
        knownLociResultsCloud = store.at(googleOutDir / s"${projectId}.${arrayId}.assoc.$knownLociPhenoName.$knownLociTrans.$knownLociCovarsString.$knownLociTest.known_loci.results.tsv"))

    }

    val sampleqcBase = s"${projectId}.${arrayId}.sampleqc"
    val sampleqcStatsAdjBase = s"${sampleqcBase}.stats.adj"
  
    val paramsByArrByMetric = (0 until nMetrics).map { metricIdx =>
    
      val sampleqcStatsAdjIndMetric = sampleQcMetrics(metricIdx)
      val sampleqcStatsAdjIndClusterBase = s"${sampleqcStatsAdjBase}.${sampleqcStatsAdjIndMetric}"
    
      metricIdx -> Metric(
        sampleqcStatsAdjIndMetric = sampleqcStatsAdjIndMetric,
        sampleqcStatsAdjIndClusterName = localOutDir / sampleqcStatsAdjIndClusterBase,
        sampleqcStatsAdjIndClusterFet = store.at(localOutDir / s"${sampleqcStatsAdjIndClusterBase}.fet.1"),
        sampleqcStatsAdjIndClusterClu = store.at(localOutDir / s"${sampleqcStatsAdjIndClusterBase}.clu.1"),
        sampleqcStatsAdjIndClusterKlg = store.at(localOutDir / s"${sampleqcStatsAdjIndClusterBase}.klg.1"),
        sampleqcStatsAdjIndClusterKlustakwikLog = store.at(localOutDir / s"${sampleqcStatsAdjIndClusterBase}.klustakwik.log"))
    }
  
    val harmBase = s"${projectId}.${arrayId}.harm"
    val harmName = localOutDir / harmBase
    val harmRefBase = s"${harmBase}.ref"
    val harmRefName = localOutDir / harmRefBase
    val harmRefFiltBase = s"${harmRefBase}.filt"
    val harmRefFiltPrunedBase = s"${harmRefFiltBase}.pruned"
    val harmRefFiltPrunedName = localOutDir / harmRefFiltPrunedBase
    val harmRefFiltPrunedNameCloud = googleOutDir / s"${harmRefFiltBase}.pruned"
    val harmRefFiltName = localOutDir / harmRefFiltBase
    val kinBase = s"${projectId}.${arrayId}.kinship"
    val harmRef1kgBase = s"${projectId}.${arrayId}.harm.ref.1kg"
    val harmRef1kgName = localOutDir / harmRef1kgBase
    val harmRef1kgNameCloud = googleOutDir / harmRef1kgBase
    val pcaBase = s"${projectId}.${arrayId}.pca"
    val ancestryBase = s"${projectId}.${arrayId}.ancestry"
    val ancestryPcaBase = s"${ancestryBase}.pca"
    val ancestryClusterBase = s"${projectId}.${arrayId}.ancestry.cluster"
    val sampleqcSexcheckBase = s"${projectId}.${arrayId}.sampleqc.sexcheck"
    val sampleqcStatsAdjOutliersTableBase = s"${sampleqcBase}.outliers.tsv"
    val finalBase = s"${projectId}.${arrayId}.final"
    val cleanBase = s"${projectId}.${arrayId}.clean"
    val cleanName = localOutDir / cleanBase
    val cleanNameCloud = googleOutDir / cleanBase
    val sampleqcStatsAdjClusterBase = s"${sampleqcBase}.stats.adj.cluster"
    val sampleqcStatsAdjClusterName = localOutDir / sampleqcStatsAdjClusterBase
    val variantqcBase = s"${projectId}.${arrayId}.variantqc"
  
    val (_, paramsByArrByChrSorted) = paramsByArrByChr.unzip
    val harmMergeLines = paramsByArrByChrSorted.map(_.harmKgHuRefChrName.toString)
    val (_, paramsByArrByModelSorted) = paramsByArrByModel.unzip
    val (_, paramsByArrByKnownLociSorted) = paramsByArrByKnownLoci.unzip
    val (_, paramsByArrByMetricSorted) = paramsByArrByMetric.unzip
    val sampleqcStatsAdjIndClusterCluList = paramsByArrByMetricSorted.map(_.sampleqcStatsAdjIndClusterClu.toString)
  
    arr -> Arr(
    arrayId = arrayId,
    arrayDataPath = arrayDataPath,
    arrayDataType = arrayDataType,
    arrayData = arrayData,
    arrayDataRawName = arrayDataRawName,
    arrayDataRawUnplaced = store.at(s"${arrayDataRawName}.unplaced"),
    arrayDataRawUnique = store.at(s"${arrayDataRawName}.unique"),
    arrayDataRawIndel = store.at(s"${arrayDataRawName}.indel"),
    arrayDataRawLmiss = store.at(s"${arrayDataRawName}.missing.lmiss"),
    arrayDataRawFreq = store.at(s"${arrayDataRawName}.freq.frq"),
    arrayDataRawMono = store.at(s"${arrayDataRawName}.mono"),
    arrayDataRawDupRemove = store.at(s"${arrayDataRawName}.duplicates.exclude"),
    arrayDataPreparedName = arrayDataPreparedName,
    arrayDataPrepared = bedBimFam(arrayDataPreparedName),
    arrayDataPreparedMultiallelic = store.at(s"${arrayDataPreparedName}.multiallelic"),
    paramsByArrByChr = paramsByArrByChr,
    paramsByArrByModel = paramsByArrByModel,
    paramsByArrByKnownLoci = paramsByArrByKnownLoci,
    paramsByArrByMetric = paramsByArrByMetric,
    harmName = harmName,
    harm = bedBimFam(harmName),
    harmRefName = harmRefName,
    harmNonKgRemove = store.at(localOutDir / s"${harmBase}.nonkg.variants.removed.txt"),
    harmNonKgIgnore = store.at(localOutDir / s"${harmBase}.nonkg.variants.ignored.txt"),
    harmNonKgMono = store.at(localOutDir / s"${harmBase}.nonkg.variants.removed_mono.txt"),
    harmNonKgNomatch = store.at(localOutDir / s"${harmBase}.nonkg.variants.removed_nomatch.txt"),
    harmNonKgFlip = store.at(localOutDir / s"${harmBase}.nonkg.variants.flipped.txt"),
    harmNonKgForceA1 = store.at(localOutDir / s"${harmBase}.nonkg.variants.forced_a1.txt"),
    harmKgVarSnpLog = store.at(localOutDir / s"${harmBase}_snpLog.log"),
    harmRef = bedBimFam(harmRefName),
    harmRefVcf = store.at(localOutDir / s"${harmRefBase}.vcf.gz"),
    harmRefVcfCloud = store.at(googleOutDir / s"${harmRefBase}.vcf.gz"),
    harmRefVcfTbi = store.at(localOutDir / s"${harmRefBase}.vcf.gz.tbi"),
    harmRefVcfTbiCloud = store.at(googleOutDir / s"${harmRefBase}.vcf.gz.tbi"),
    harmRefVdsCloud = store.at(googleOutDir / s"${harmRefBase}.vds"),
    paramsByArrByChrSorted = paramsByArrByChrSorted,
    paramsByArrByModelSorted = paramsByArrByModelSorted,
    paramsByArrByKnownLociSorted = paramsByArrByKnownLociSorted,
    paramsByArrByMetricSorted = paramsByArrByMetricSorted,
    harmMergeLines = harmMergeLines,
    sampleqcStatsAdjIndClusterCluList = sampleqcStatsAdjIndClusterCluList,
    harmMergeList = store.at(localOutDir / s"${harmBase}.merge.txt"),
    harmForceA2 = store.at(localOutDir / s"${harmBase}.force_a2.txt"),
    harmRefFiltNameCloud = googleOutDir / harmRefFiltBase,
    harmRefFiltCloud = bedBimFam(googleOutDir / harmRefFiltBase),
    harmRefFiltVdsCloud = store.at(googleOutDir / s"${harmRefFiltBase}.vds"),
    harmRefFiltVariantQcCloud = store.at(googleOutDir / s"${harmRefFiltBase}.variantqc.tsv"),
    harmRefFiltVariantsPrunedInCloud = store.at(googleOutDir / s"${harmRefFiltPrunedBase}.in"),
    harmRefFiltPrunedName = harmRefFiltPrunedName,
    harmRefFiltPruned = bedBimFam(harmRefFiltPrunedName),
    harmRefFiltPrunedNameCloud = harmRefFiltPrunedNameCloud,
    harmRefFiltPrunedCloud = bedBimFam(harmRefFiltPrunedNameCloud),
    harmRefFiltPrunedVdsCloud = store.at(googleOutDir / s"${harmRefFiltPrunedBase}.vds"),
    kinName = localOutDir / kinBase,
    kinLog = store.at(localOutDir / s"${kinBase}.log"),
    kinTmpDat = store.at(localOutDir / s"${kinBase}TMP.dat"),
    kinTmpPed = store.at(localOutDir / s"${kinBase}TMP.ped"),
    kinKin = store.at(localOutDir / s"${kinBase}.kin"),
    kinKin0 = store.at(localOutDir / s"${kinBase}.kin0"),
    kinKin0Related = store.at(localOutDir / s"${kinBase}.kin0.related"),
    kinFamsizes = store.at(localOutDir / s"${kinBase}.famsizes.tsv"),
    ancestryPcaName = localOutDir / ancestryPcaBase,
    harmRef1kgName = harmRef1kgName,
    harmRef1kg = bedBimFam(harmRef1kgName),
    harmRef1kgGds = store.at(localOutDir / s"${harmRef1kgBase}.gds"),
    ancestryPcaLog = store.at(localOutDir / s"${ancestryPcaBase}.log"),
    ancestryPcaScores = store.at(localOutDir / s"${ancestryPcaBase}.scores.tsv"),
    ancestryPcaScoresPlots = store.at(localOutDir / s"${ancestryPcaBase}.scores.plots.pdf"),
    ancestryPcaScoresPlotPc1VsPc2 = store.at(localOutDir / s"${ancestryPcaBase}.scores.plot.pc1vspc2.png"),
    ancestryPcaScoresPlotPc2VsPc3 = store.at(localOutDir / s"${ancestryPcaBase}.scores.plot.pc2vspc3.png"),
    harmRef1kgNameCloud = harmRef1kgNameCloud,
    harmRef1kgCloud = bedBimFam(harmRef1kgNameCloud),
    ancestryClusterName = localOutDir / ancestryClusterBase,
    ancestryClusterLog = store.at(localOutDir / s"${ancestryClusterBase}.log"),
    ancestryClusterFet = store.at(localOutDir / s"${ancestryClusterBase}.fet.1"),
    ancestryClusterClu = store.at(localOutDir / s"${ancestryClusterBase}.clu.1"),
    ancestryClusterKlg = store.at(localOutDir / s"${ancestryClusterBase}.klg.1"),
    ancestryClusterPlots = store.at(localOutDir / s"${ancestryClusterBase}.plots.pdf"),
    ancestryClusterPlotPc1VsPc2 = store.at(localOutDir / s"${ancestryClusterBase}.plot.pc1vspc2.png"),
    ancestryClusterPlotPc2VsPc3 = store.at(localOutDir / s"${ancestryClusterBase}.plot.pc2vspc3.png"),
    ancestryClusterPlotsCenters = store.at(localOutDir / s"${ancestryClusterBase}.plots.centers.pdf"),
    ancestryClusterPlotsNo1kg = store.at(localOutDir / s"${ancestryClusterBase}.plots.no_1kg.pdf"),
    ancestryClusterXtabs = store.at(localOutDir / s"${ancestryClusterBase}.xtabs"),
    ancestryClusterGroups = store.at(localOutDir / s"${ancestryClusterBase}.groups.tsv"),
    ancestryInferred = store.at(localOutDir / s"${ancestryBase}.inferred.tsv"),
    harmRefFiltPrunedPcaGds = store.at(localOutDir / s"${harmRefFiltPrunedBase}.pca.gds"),
    pcaLog = store.at(localOutDir / s"${pcaBase}.log"),
    pcaScores = store.at(localOutDir / s"${pcaBase}.scores.tsv"),
    sampleqcStats = store.at(localOutDir / s"${sampleqcBase}.stats.tsv"),
    sampleqcStatsAdj = store.at(localOutDir / s"${sampleqcBase}.stats.adj.tsv"),
    sampleqcStatsAdjCorrPlots = store.at(localOutDir / s"${sampleqcBase}.stats.adj.corr.pdf"),
    sampleqcStatsAdjPcaLoadings = store.at(localOutDir / s"${sampleqcBase}.stats.adj.pca.loadings.tsv"),
    sampleqcStatsAdjPcaScoresPlots = store.at(localOutDir / s"${sampleqcBase}.stats.adj.pca.plots.pdf"),
    sampleqcStatsAdjPcaScores = store.at(localOutDir / s"${sampleqcBase}.stats.adj.pca.scores.tsv"),
    sampleqcSexcheck = store.at(localOutDir / s"${sampleqcSexcheckBase}.tsv"),
    sampleqcSexcheckProblems = store.at(localOutDir / s"${sampleqcSexcheckBase}.problems.tsv"),
    sampleqcSexcheckCloud = store.at(googleOutDir / s"${sampleqcSexcheckBase}.tsv"),
    sampleqcSexcheckProblemsCloud = store.at(googleOutDir / s"${sampleqcSexcheckBase}.problems.tsv"),
    sampleqcStatsCloud = store.at(googleOutDir / s"${sampleqcBase}.stats.tsv"),
    sampleqcStatsAdjClusterName = sampleqcStatsAdjClusterName,
    sampleqcStatsAdjClusterFet = store.at(localOutDir / s"${sampleqcStatsAdjClusterBase}.fet.1"),
    sampleqcStatsAdjClusterClu = store.at(localOutDir / s"${sampleqcStatsAdjClusterBase}.clu.1"),
    sampleqcStatsAdjClusterKlg = store.at(localOutDir / s"${sampleqcStatsAdjClusterBase}.klg.1"),
    sampleqcStatsAdjClusterKlustakwikLog = store.at(localOutDir / s"${sampleqcStatsAdjClusterBase}.klustakwik.log"),
    sampleqcStatsAdjClusterOutliers = store.at(localOutDir / s"${sampleqcBase}.stats.adj.cluster.outliers"),
    sampleqcStatsAdjClusterPlots = store.at(localOutDir / s"${sampleqcBase}.stats.adj.cluster.plots.pdf"),
    sampleqcStatsAdjClusterXtabs = store.at(localOutDir / s"${sampleqcBase}.stats.adj.cluster.xtabs"),
    sampleqcStatsAdjIndBoxplots = store.at(localOutDir / s"${sampleqcBase}.stats.adj.ind.boxplots.pdf"),
    sampleqcStatsAdjIndDiscreteness = store.at(localOutDir / s"${sampleqcBase}.stats.adj.ind.discreteness"),
    sampleqcStatsAdjOutliersTable = store.at(localOutDir / sampleqcStatsAdjOutliersTableBase),
    sampleqcOutlierPlotPdf = store.at(localOutDir / s"${sampleqcBase}.outlier.plot.pdf"),
    sampleqcOutlierPlotPng = store.at(localOutDir / s"${sampleqcBase}.outlier.plot.png"),
    sampleqcStatsAdjStripchart = store.at(localOutDir / s"${sampleqcBase}.stats.adj.stripchart.pdf"),
    finalSampleExclusions = store.at(localOutDir / s"${finalBase}.sample.exclusions"),
    finalSampleExclusionsCloud = store.at(googleOutDir / s"${finalBase}.sample.exclusions"),
    variantqcStats = store.at(localOutDir / s"${variantqcBase}.stats.tsv"),
    variantqcStatsCloud = store.at(googleOutDir / s"${variantqcBase}.stats.tsv"),
    finalVariantExclusions = store.at(localOutDir / s"${finalBase}.variant.exclusions"),
    finalVariantExclusionsCloud = store.at(googleOutDir / s"${finalBase}.variant.exclusions"),
    cleanName = cleanName,
    clean = bedBimFam(cleanName),
    cleanGds = store.at(localOutDir / s"${cleanBase}.gds"),
    cleanPcaScores = store.at(localOutDir / s"${cleanBase}.pca.scores.tsv"),
    cleanPcaLog = store.at(localOutDir / s"${cleanBase}.pca.log"),
    cleanNameCloud = cleanNameCloud,
    cleanCloud = bedBimFam(cleanNameCloud),
    cleanVcf = store.at(localOutDir / s"${cleanBase}.vcf.bgz"),
    cleanVcfTbi = store.at(localOutDir / s"${cleanBase}.vcf.bgz.tbi"),
    cleanVcfCloud = store.at(googleOutDir / s"${cleanBase}.vcf.bgz"),
    cleanVdsCloud = store.at(googleOutDir / s"${cleanBase}.vds"))
  }

  val (_, paramsByArrSorted) = paramsByArr.unzip
  val (_, paramsByResultSorted) = paramsByResult.unzip
  val (_, paramsByResultKnownLociSorted) = paramsByResultKnownLoci.unzip

}

// Perform qc1
val ancestryInferredStores: Seq[Store] = {

  for {
    i <- 0 until nArrays
  } yield { 

    qc1(i)

  }

}

// Reconcile inferred ancestry step
val ancestryInferredPathList = ancestryInferredStores.map(_.path).mkString(",")
val ancestryInferredMerged = store.at(localOutDir / s"${projectId}.ancestry.inferred.merged.tsv")
val ancestryInferredMergedCloud = store.at(googleOutDir / s"${projectId}.ancestry.inferred.merged.tsv")
val ancestryInferredMergedOutliers = store.at(localOutDir / s"${projectId}.ancestry.inferred.merged.outliers.tsv")

uger {

  cmd"""$binRscript --vanilla --verbose
    $rAncestryClusterMerge
    --ancestry-in $ancestryInferredPathList
    --out-table ${ancestryInferredMerged}
    --out-outliers ${ancestryInferredMergedOutliers}""".in(ancestryInferredStores).out(ancestryInferredMerged, ancestryInferredMergedOutliers).using("R-3.4")

}

// Perform qc2, adding relevent (inter-array) stores to the map
val resultsStoresMapsList: Seq[Map[(String, String, String, String, String), Store]] = {

  for {
    i <- 0 until nArrays
  } yield { 

    qc2(i)

  }

}

// Merge results step
for {
  i <- 0 until modelSeq.size
} {

  mergeResults(i)

}

// Perform qc2, adding relevent (inter-array) stores to the map
val resultsKnownLociStoresMapsList: Seq[Map[(String, String, String, String, String, String), Store]] = {

  for {
    i <- 0 until nArrays
  } yield { 

    qc3(i)

  }

}

// Merge results step
for {
  i <- 0 until knownLociSeq.size
} {

  mergeKnownLoci(i)

}

// Generate regional plots after merge results step
andThen {

  val resultsFinalRegplots: Seq[Seq[Store]] = {

    for {
      i <- 0 until modelSeq.size
    } yield { 

      plotSigRegions(i)

    }

  }

  // Generate qc report files
  val reportQcIntro = store.at(localOutDir / s"${projectId}.qcreport.intro.tex")
  val reportQcData = store.at(localOutDir / s"${projectId}.qcreport.data.tex")
  val reportQcAncestry = store.at(localOutDir / s"${projectId}.qcreport.ancestry.tex")
  val reportQcIbdSexcheck = store.at(localOutDir / s"${projectId}.qcreport.ibd_sexcheck.tex")
  val reportQcSampleqc = store.at(localOutDir / s"${projectId}.qcreport.sampleqc.tex")
  val reportQcVariantqc = store.at(localOutDir / s"${projectId}.qcreport.variantqc.tex")
  val reportQcBibliography = store.at(localOutDir / s"${projectId}.qcreport.bibliography.tex")
  val reportQcTex = store.at(localOutDir / s"${projectId}.qcreport.tex")
  val reportQcPdf = store.at(localOutDir / s"${projectId}.qcreport.pdf")
  val reportQcSampleUpsetplotPdf = store.at(localOutDir / s"${projectId}.qcreport.samples.upsetplot.pdf")
  val reportQcSampleUpsetplotPng = store.at(localOutDir / s"${projectId}.qcreport.samples.upsetplot.png")
  val reportQcVariantsRemainingUpsetplotPdf = store.at(localOutDir / s"${projectId}.qcreport.variants_remaining.upsetplot.pdf")
  val reportQcVariantsRemainingUpsetplotPng = store.at(localOutDir / s"${projectId}.qcreport.variants_remaining.upsetplot.png")
  val reportQcSamplesRemainingUpsetplotPdf = store.at(localOutDir / s"${projectId}.qcreport.samples_remaining.upsetplot.pdf")
  val reportQcSamplesRemainingUpsetplotPng = store.at(localOutDir / s"${projectId}.qcreport.samples_remaining.upsetplot.png")
  val reportQcVariantUpsetplotPdf = store.at(localOutDir / s"${projectId}.qcreport.variants.upsetplot.pdf")
  val reportQcVariantUpsetplotPng = store.at(localOutDir / s"${projectId}.qcreport.variants.upsetplot.png")
  val reportQcSampleqcTable = store.at(localOutDir / s"${projectId}.qcreport.sampleqc.tbl")
  val reportQcVariantSummaryTable = store.at(localOutDir / s"${projectId}.qcreport.variants.summary.tbl")
  val reportQcAncestryClusterTable = store.at(localOutDir / s"${projectId}.qcreport.ancestry.clusters.tbl")
  val reportQcAncestryFinalTable = store.at(localOutDir / s"${projectId}.qcreport.ancestry.final.tbl")
  val sampleQcMetricDistUnadjPdf = store.at(localOutDir / s"${projectId}.qcreport.sampleqc.metric_dist_unadj.pdf")
  val sampleQcMetricDistAdjPdf = store.at(localOutDir / s"${projectId}.qcreport.sampleqc.metric_dist_adj.pdf")
  val sampleQcMetricDistUnadjPng = store.at(localOutDir / s"${projectId}.qcreport.sampleqc.metric_dist_unadj.png")
  val sampleQcMetricDistAdjPng = store.at(localOutDir / s"${projectId}.qcreport.sampleqc.metric_dist_adj.png")
  var arrayDataStrings = Seq[String]()
  var harmRefFamStrings = Seq[String]()
  var harmRefBimStrings = Seq[String]()
  var arrayFrqStrings = Seq[String]()
  var arrayIndelStrings = Seq[String]()
  var arrayMultiStrings = Seq[String]()
  var arrayDuplStrings = Seq[String]()
  var arrayMergedKgBims = Seq[String]()
  var arrayClusterGroups = Seq[String]()
  var arrayAncestryInferred = Seq[String]()
  var arrayPcaScoresPlots = Seq[String]()
  var arrayClusterPlots = Seq[String]()
  var arrayharmRefFilteredBims = Seq[String]()
  var arrayKin0Related = Seq[String]()
  var arrayFamsizes = Seq[String]()
  var arraySexcheckProblems = Seq[String]()
  var arraySampleqcOutliers = Seq[String]()
  var arrayFinalSampleExclusions = Seq[String]()
  var arrayFinalVariantExclusions = Seq[String]()
  var arraySampleqcOutlierPlots = Seq[String]()
  var arrayCleanFamStrings = Seq[String]()
  var arrayCleanBimStrings = Seq[String]()

  for { 
    i <- 0 until nArrays
  } {

    val (_, paramsArr) = Params.paramsByArr(i)

    arrayDataStrings = arrayDataStrings :+ paramsArr.arrayDataType + "___" + paramsArr.arrayDataPath
    harmRefFamStrings = harmRefFamStrings :+ paramsArr.arrayId + "___" + paramsArr.harmRefName + ".fam"
    harmRefBimStrings = harmRefBimStrings :+ paramsArr.arrayId + "___" + paramsArr.harmRefName + ".bim"

    arrayFrqStrings = arrayFrqStrings :+ paramsArr.arrayId + "___" + s"${paramsArr.arrayDataRawFreq.toString.split("@")(1)}"
    arrayMultiStrings = arrayMultiStrings :+ paramsArr.arrayId + "___" + s"${paramsArr.arrayDataPreparedMultiallelic.toString.split("@")(1)}"
    arrayIndelStrings = arrayIndelStrings :+ paramsArr.arrayId + "___" + s"${paramsArr.arrayDataRawIndel.toString.split("@")(1)}"
    arrayDuplStrings = arrayDuplStrings :+ paramsArr.arrayId + "___" + s"${paramsArr.arrayDataRawDupRemove.toString.split("@")(1)}"

    arrayMergedKgBims = arrayMergedKgBims :+ paramsArr.arrayId + "___" + s"${paramsArr.harmRef1kgName}.bim"
    arrayClusterGroups = arrayClusterGroups :+ paramsArr.arrayId + "___" + s"${paramsArr.ancestryClusterGroups.toString.split("@")(1)}"
    arrayAncestryInferred = arrayAncestryInferred :+ paramsArr.arrayId + "___" + s"${paramsArr.ancestryInferred.toString.split("@")(1)}"
    arrayPcaScoresPlots = arrayPcaScoresPlots :+ paramsArr.arrayId + "___" + s"${paramsArr.ancestryPcaScoresPlotPc1VsPc2.toString.split("@")(1)}" + "___" + s"${paramsArr.ancestryPcaScoresPlotPc2VsPc3.toString.split("@")(1)}"
    arrayClusterPlots = arrayClusterPlots :+ paramsArr.arrayId + "___" + s"${paramsArr.ancestryClusterPlotPc1VsPc2.toString.split("@")(1)}" + "___" + s"${paramsArr.ancestryClusterPlotPc2VsPc3.toString.split("@")(1)}"

    arrayharmRefFilteredBims = arrayharmRefFilteredBims :+ paramsArr.arrayId + "___" + s"${paramsArr.harmRefFiltPrunedName}.bim"
    arrayKin0Related = arrayKin0Related :+ paramsArr.arrayId + "___" + s"${paramsArr.kinKin0Related.toString.split("@")(1)}"
    arrayFamsizes = arrayFamsizes :+ paramsArr.arrayId + "___" + s"${paramsArr.kinFamsizes.toString.split("@")(1)}"
    arraySexcheckProblems = arraySexcheckProblems :+ paramsArr.arrayId + "___" + s"${paramsArr.sampleqcSexcheckProblems.toString.split("@")(1)}"

    arraySampleqcOutliers = arraySampleqcOutliers :+ paramsArr.arrayId + "___" + s"${paramsArr.sampleqcStatsAdjOutliersTable.toString.split("@")(1)}"
    arrayFinalSampleExclusions = arrayFinalSampleExclusions :+ paramsArr.arrayId + "___" + s"${paramsArr.finalSampleExclusions.toString.split("@")(1)}"
    arrayFinalVariantExclusions = arrayFinalVariantExclusions :+ paramsArr.arrayId + "___" + s"${paramsArr.finalVariantExclusions.toString.split("@")(1)}"
    arraySampleqcOutlierPlots = arraySampleqcOutlierPlots :+ paramsArr.arrayId + "___" + s"${paramsArr.sampleqcOutlierPlotPng.toString.split("@")(1)}"

    arrayCleanFamStrings = arrayCleanFamStrings :+ paramsArr.arrayId + "___" + s"${paramsArr.cleanName}.fam"
    arrayCleanBimStrings = arrayCleanBimStrings :+ paramsArr.arrayId + "___" + s"${paramsArr.cleanName}.bim"

  }
  
  uger {
  
    cmd"""$binRscript --vanilla --verbose
      $rVariantsSummaryTable
      --freq-in "${arrayFrqStrings.mkString(",")}"
      --indel-in "${arrayIndelStrings.mkString(",")}"
      --multi-in "${arrayMultiStrings.mkString(",")}"
      --dupl-in "${arrayDuplStrings.mkString(",")}"
      --out ${reportQcVariantSummaryTable}"""
      .in(Params.paramsByArrSorted.map(_.arrayDataRawFreq) ++ Params.paramsByArrSorted.map(_.arrayDataPreparedMultiallelic) ++ Params.paramsByArrSorted.map(_.arrayDataRawIndel) ++ Params.paramsByArrSorted.map(_.arrayDataRawDupRemove))
      .out(reportQcVariantSummaryTable)
      .using("R-3.4")
  
    cmd"""$binRscript --vanilla --verbose
      $rUpsetplotBimFam
      --input "${harmRefFamStrings.mkString(",")}"
      --type fam
      --out $reportQcSampleUpsetplotPdf"""
      .in(Params.paramsByArrSorted.map(_.arrayData))
      .out(reportQcSampleUpsetplotPdf)
      .using("R-3.4")
  
    cmd"""$binConvert -density 300 -depth 8 -quality 100 -flatten ${reportQcSampleUpsetplotPdf}[0] $reportQcSampleUpsetplotPng"""
      .in(reportQcSampleUpsetplotPdf)
      .out(reportQcSampleUpsetplotPng)
  
    cmd"""$binRscript --vanilla --verbose
      $rUpsetplotBimFam
      --input "${harmRefBimStrings.mkString(",")}"
      --type bim
      --out $reportQcVariantUpsetplotPdf"""
      .in(Params.paramsByArrSorted.flatMap(_.harm))
      .out(reportQcVariantUpsetplotPdf)
      .using("R-3.4")
  
    cmd"""$binConvert -density 300 -depth 8 -quality 100 -flatten ${reportQcVariantUpsetplotPdf}[0] $reportQcVariantUpsetplotPng"""
      .in(reportQcVariantUpsetplotPdf)
      .out(reportQcVariantUpsetplotPng)
  
    cmd"""$binRscript --vanilla --verbose
      $rAncestryClusterTable
      --cluster-in "${arrayClusterGroups.mkString(",")}"
      --ancestry-in "${arrayAncestryInferred.mkString(",")}"
      --final-in ${ancestryInferredMerged}
      --cluster-out ${reportQcAncestryClusterTable}
      --final-out ${reportQcAncestryFinalTable}"""
      .in(Params.paramsByArrSorted.map(_.ancestryClusterGroups) ++ Params.paramsByArrSorted.map(_.ancestryInferred) :+ ancestryInferredMerged)
      .out(reportQcAncestryClusterTable, reportQcAncestryFinalTable)
      .using("R-3.4")
  
    cmd"""python $pyGenerateQcReportIntro
      --id $projectId
      --authors "$qcReportAuthors" 
      --out ${reportQcIntro} 
      --array-data ${arrayDataStrings.mkString(",")}"""
      .in(Params.paramsByArrSorted.map(_.arrayData))
      .out(reportQcIntro)
  
    cmd"""python $pyGenerateQcReportData
      --narrays $nArrays
      --samples-upset-diagram ${reportQcSampleUpsetplotPng}
      --variants-summary-table ${reportQcVariantSummaryTable} 
      --variants-upset-diagram ${reportQcVariantUpsetplotPng} 
      --out ${reportQcData}"""
      .in(reportQcSampleUpsetplotPng, reportQcVariantSummaryTable)
      .out(reportQcData)
  
    cmd"""python $pyGenerateQcReportAncestry
      --kg-merged-bim "${arrayMergedKgBims.mkString(",")}"
      --pca-plots "${arrayPcaScoresPlots.mkString(",")}"
      --cluster-plots "${arrayClusterPlots.mkString(",")}"
      --cluster-table ${reportQcAncestryClusterTable}
      --final-table ${reportQcAncestryFinalTable}
      --out ${reportQcAncestry}"""
      .in(Params.paramsByArrSorted.flatMap(_.harmRef1kg) ++ Params.paramsByArrSorted.map(_.ancestryPcaScoresPlotPc1VsPc2) ++ Params.paramsByArrSorted.map(_.ancestryPcaScoresPlotPc2VsPc3) ++ Params.paramsByArrSorted.map(_.ancestryClusterPlotPc1VsPc2) ++ Params.paramsByArrSorted.map(_.ancestryClusterPlotPc2VsPc3) :+ reportQcAncestryClusterTable :+ reportQcAncestryFinalTable)
      .out(reportQcAncestry)
  
    cmd"""python $pyGenerateQcReportIbdSexcheck
      --filtered-bim "${arrayharmRefFilteredBims.mkString(",")}"
      --kin0-related "${arrayKin0Related.mkString(",")}"
      --famsizes "${arrayFamsizes.mkString(",")}"
      --sexcheck-problems "${arraySexcheckProblems.mkString(",")}"
      --out ${reportQcIbdSexcheck}"""
      .in(Params.paramsByArrSorted.flatMap(_.harmRefFiltPruned) ++ Params.paramsByArrSorted.map(_.kinKin0Related) ++ Params.paramsByArrSorted.map(_.kinFamsizes) ++ Params.paramsByArrSorted.map(_.sampleqcSexcheckProblems))
      .out(reportQcIbdSexcheck)
  
    cmd"""$binRscript --vanilla --verbose
      $rMakeMetricDistPlot
      --sampleqc ${Params.paramsByArrSorted.head.sampleqcStats}
      --metric nHet
      --out ${sampleQcMetricDistUnadjPdf}
      """
      .in(Params.paramsByArrSorted.head.sampleqcStats)
      .out(sampleQcMetricDistUnadjPdf)
  
    cmd"""$binConvert -density 300 -depth 8 -quality 100 -flatten ${sampleQcMetricDistUnadjPdf}[0] $sampleQcMetricDistUnadjPng"""
      .in(sampleQcMetricDistUnadjPdf)
      .out(sampleQcMetricDistUnadjPng)
  
    cmd"""$binRscript --vanilla --verbose
      $rMakeMetricDistPlot
      --sampleqc ${Params.paramsByArrSorted.head.sampleqcStatsAdj}
      --metric nHet_res
      --out ${sampleQcMetricDistAdjPdf}
      """
      .in(Params.paramsByArrSorted.head.sampleqcStatsAdj)
      .out(sampleQcMetricDistAdjPdf)
  
    cmd"""$binConvert -density 300 -depth 8 -quality 100 -flatten ${sampleQcMetricDistAdjPdf}[0] $sampleQcMetricDistAdjPng"""
      .in(sampleQcMetricDistAdjPdf)
      .out(sampleQcMetricDistAdjPng)
  
    cmd"""$binRscript --vanilla --verbose
      $rMakeOutlierTable
      --ancestry-inferred-outliers ${ancestryInferredMergedOutliers}
      --kinship-related ${arrayKin0Related.mkString(",")}
      --kinship-famsizes ${arrayFamsizes.mkString(",")}
      --sampleqc-outliers ${arraySampleqcOutliers.mkString(",")}
      --sexcheck-problems ${arraySexcheckProblems.mkString(",")}
      --final-exclusions ${arrayFinalSampleExclusions.mkString(",")}
      --out ${reportQcSampleqcTable}"""
      .in(Params.paramsByArrSorted.map(_.kinKin0Related) ++ Params.paramsByArrSorted.map(_.kinFamsizes) ++ Params.paramsByArrSorted.map(_.sampleqcStatsAdjOutliersTable) ++ Params.paramsByArrSorted.map(_.sampleqcSexcheckProblems) ++ Params.paramsByArrSorted.map(_.finalSampleExclusions) :+ ancestryInferredMergedOutliers)
      .out(reportQcSampleqcTable)
  
    cmd"""$binRscript --vanilla --verbose
      $rUpsetplotBimFam
      --input "${arrayCleanFamStrings.mkString(",")}"
      --type fam
      --ancestry ${ancestryInferredMerged}
      --out ${reportQcSamplesRemainingUpsetplotPdf}"""
      .in(Params.paramsByArrSorted.flatMap(_.clean) :+ ancestryInferredMerged)
      .out(reportQcSamplesRemainingUpsetplotPdf)
      .using("R-3.4")
  
    cmd"""$binConvert -density 300 -depth 8 -quality 100 -flatten ${reportQcSamplesRemainingUpsetplotPdf}[0] $reportQcSamplesRemainingUpsetplotPng"""
      .in(reportQcSamplesRemainingUpsetplotPdf)
      .out(reportQcSamplesRemainingUpsetplotPng)
  
    cmd"""python $pyGenerateQcReportSampleqc
      --compare-dist-nhet-unadj ${sampleQcMetricDistUnadjPng}
      --compare-dist-nhet-adj ${sampleQcMetricDistAdjPng}
      --compare-dist-nhet-label ${Params.paramsByArrSorted.head.arrayId}
      --sampleqc-outliers ${arraySampleqcOutlierPlots.mkString(",")}
      --sampleqc-summary-table ${reportQcSampleqcTable}
      --samples-upset-diagram ${reportQcSamplesRemainingUpsetplotPng}
      --out ${reportQcSampleqc}"""
      .in(Params.paramsByArrSorted.map(_.sampleqcOutlierPlotPng) :+ sampleQcMetricDistUnadjPng :+ sampleQcMetricDistAdjPng :+ reportQcSampleqcTable :+ reportQcSamplesRemainingUpsetplotPng)
      .out(reportQcSampleqc)
  
    cmd"""$binRscript --vanilla --verbose
      $rUpsetplotBimFam
      --input "${arrayCleanBimStrings.mkString(",")}"
      --type bim
      --out ${reportQcVariantsRemainingUpsetplotPdf}"""
      .in(Params.paramsByArrSorted.flatMap(_.clean))
      .out(reportQcVariantsRemainingUpsetplotPdf)
      .using("R-3.4")
  
    cmd"""$binConvert -density 300 -depth 8 -quality 100 -flatten ${reportQcVariantsRemainingUpsetplotPdf}[0] $reportQcVariantsRemainingUpsetplotPng"""
      .in(reportQcVariantsRemainingUpsetplotPdf)
      .out(reportQcVariantsRemainingUpsetplotPng)
  
    cmd"""python $pyGenerateQcReportVariantqc
      --variants-upset-diagram ${reportQcVariantsRemainingUpsetplotPng}
      --variant-exclusions "${arrayFinalVariantExclusions.mkString(",")}"
      --out ${reportQcVariantqc}"""
      .in(Params.paramsByArrSorted.map(_.finalVariantExclusions) :+ reportQcVariantsRemainingUpsetplotPng)
      .out(reportQcVariantqc)
  
    cmd"""python $pyGenerateQcReportBibliography
      --out ${reportQcBibliography}"""
      .out(reportQcBibliography)
  
    cmd"""cat ${reportQcIntro} ${reportQcData} ${reportQcAncestry} ${reportQcIbdSexcheck} ${reportQcSampleqc} ${reportQcVariantqc} ${reportQcBibliography} > $reportQcTex"""
      .in(reportQcIntro, reportQcData, reportQcAncestry, reportQcIbdSexcheck, reportQcSampleqc, reportQcVariantqc, reportQcBibliography)
      .out(reportQcTex)
  
    cmd"""$binPdflatex --output-directory=${localOutDir} $reportQcTex; sleep 5; $binPdflatex --output-directory=${localOutDir} $reportQcTex """
      .in(reportQcTex)
      .out(reportQcPdf)
  
  }

  // Generate analysis report files
  for {
    i <- 1 until phases.size + 1
  } {

    val modelSeqPhase = modelSeq.filter(_._6 == i)
    val reportAnalysisIntro = store.at(localOutDir / s"${projectId}.analysisreport.phase${i}.intro.tex")
    val reportAnalysisData = store.at(localOutDir / s"${projectId}.analysisreport.phase${i}.data.tex")
    val reportAnalysisIntroInput = store.at(localOutDir / s"${projectId}.analysisreport.phase${i}.intro.input")
    val reportAnalysisDataInput = store.at(localOutDir / s"${projectId}.analysisreport.phase${i}.data.input")
    val reportAnalysisStrategy = store.at(localOutDir / s"${projectId}.analysisreport.phase${i}.strategy.tex")
    val reportAnalysisStrategyInput = store.at(localOutDir / s"${projectId}.analysisreport.phase${i}.strategy.input")
    val reportAnalysisBibliography = store.at(localOutDir / s"${projectId}.analysisreport.phase${i}.bibliography.tex")
    val reportAnalysisBibliographyInput = store.at(localOutDir / s"${projectId}.analysisreport.phase${i}.bibliography.input")
    val reportAnalysisTex = store.at(localOutDir / s"${projectId}.analysisreport.phase${i}.tex")
    val reportAnalysisInput = store.at(localOutDir / s"${projectId}.analysisreport.phase${i}.input")
    val reportAnalysisPdf = store.at(localOutDir / s"${projectId}.analysisreport.phase${i}.pdf")
    var reportAnalysisResultsList = Seq[Store]()
    var reportAnalysisResultsInputList = Seq[Store]()
    var reportAnalysisResultsStringList = Seq[String]()
    var reportAnalysisResultsInputStringList = Seq[String]()
    var reportAnalysisModelTop50KnownCitation = Seq[String]()

    uger {

      cmd"""python $pyGenerateAnalysisReportIntro
        --id $projectId
        --phase $i
        --authors "$analysisReportAuthors" 
        --out-tex ${reportAnalysisIntro}
        --out-input ${reportAnalysisIntroInput}"""
        .in(Params.paramsByArrSorted.map(_.arrayData))
        .out(reportAnalysisIntro, reportAnalysisIntroInput)
      
      cmd"""python $pyGenerateAnalysisReportData
        --samples-upset-diagram ${reportQcSamplesRemainingUpsetplotPng}
        --variants-upset-diagram ${reportQcVariantsRemainingUpsetplotPng} 
        --out-tex ${reportAnalysisData}
        --out-input ${reportAnalysisDataInput}"""
        .in(reportQcSamplesRemainingUpsetplotPng, reportQcVariantsRemainingUpsetplotPng)
        .out(reportAnalysisData, reportAnalysisDataInput)
      
      cmd"""python $pyGenerateAnalysisReportStrategy
        --out-tex ${reportAnalysisStrategy}
        --out-input ${reportAnalysisStrategyInput}"""
        .out(reportAnalysisStrategy, reportAnalysisStrategyInput)

    }
      
    for {
      j <- 0 until phases(i-1).getObjList("phenotypes").size
    } {

      val phenoName = phases(i-1).getObjList("phenotypes")(j).getStr("phenoName")
      val phenoLongName = phases(i-1).getObjList("phenotypes")(j).getStr("phenoLongName")
      val reportAnalysisPhenoSummary = store.at(localOutDir / s"${projectId}.analysisreport.phase${i}.${phenoName}.summary.tex")
      val reportAnalysisPhenoSummaryInput = store.at(localOutDir / s"${projectId}.analysisreport.phase${i}.${phenoName}.summary.input")
      val reportAnalysisPhenoCalibration = store.at(localOutDir / s"${projectId}.analysisreport.phase${i}.${phenoName}.calibration.tex")
      val reportAnalysisPhenoCalibrationInput = store.at(localOutDir / s"${projectId}.analysisreport.phase${i}.${phenoName}.calibration.input")
      val reportAnalysisPhenoTopLoci = store.at(localOutDir / s"${projectId}.analysisreport.phase${i}.${phenoName}.top_loci.tex")
      val reportAnalysisPhenoTopLociInput = store.at(localOutDir / s"${projectId}.analysisreport.phase${i}.${phenoName}.top_loci.input")
      val reportAnalysisPhenoKnownLoci = store.at(localOutDir / s"${projectId}.analysisreport.phase${i}.${phenoName}.known_loci.tex")
      val reportAnalysisPhenoKnownLociInput = store.at(localOutDir / s"${projectId}.analysisreport.phase${i}.${phenoName}.known_loci.input")
      var reportAnalysisPhenoDistPlotList = Seq[Store]()
      var reportAnalysisPhenoDistStratPlotList = Seq[Store]()
      var reportAnalysisPhenoDistPlotStrings = Seq[String]()
      var reportAnalysisPhenoDistStratPlotStrings = Seq[String]()
      var reportAnalysisModelPhenoFileStrings = Seq[String]()
      var reportAnalysisModelSamplesIncludeStrings = Seq[String]()
      var reportAnalysisModelPcsFileStrings = Seq[String]()
      var reportAnalysisModelPhenoFileList = Seq[Store]()
      var reportAnalysisModelSamplesIncludeList = Seq[Store]()
      var reportAnalysisModelPcsFileList = Seq[Store]()
      var reportAnalysisModelQqPlotList = Seq[Store]()
      var reportAnalysisModelMhtPlotList = Seq[Store]()
      var reportAnalysisModelTop20AnnotAlignedRiskList = Seq[Store]()
      var reportAnalysisModelTop50KnownList = Seq[Store]()
      var reportAnalysisModelRegplotsList = Seq[Store]()
      var reportAnalysisModelQqPlotStrings = Seq[String]()
      var reportAnalysisModelMhtPlotStrings = Seq[String]()
      var reportAnalysisModelRegplotsStrings = Seq[String]()
      var reportAnalysisModelTop20AnnotAlignedRiskStrings = Seq[String]()
      var reportAnalysisModelTop50KnownStrings = Seq[String]()
      var reportAnalysisModelTop50KnownDesc = Seq[String]()
      var reportAnalysisModelTop50KnownTag = Seq[String]()

      for {
        k <- 0 until nArrays
      } {

          val (_, paramsArr) = Params.paramsByArr(k)
          val reportAnalysisPhenoDistPlot = store.at(localOutDir / s"${projectId}.analysisreport.phase${i}.${paramsArr.arrayId}.${phenoName}.dist.png")
          val reportAnalysisPhenoDistStratPlot = store.at(localOutDir / s"${projectId}.analysisreport.phase${i}.${paramsArr.arrayId}.${phenoName}.dist.strat.png")

          reportAnalysisPhenoDistPlotStrings = reportAnalysisPhenoDistPlotStrings :+ paramsArr.arrayId + "___" + s"${reportAnalysisPhenoDistPlot.toString.split("@")(1)}"
          reportAnalysisPhenoDistStratPlotStrings = reportAnalysisPhenoDistStratPlotStrings :+ paramsArr.arrayId + "___" + s"${reportAnalysisPhenoDistStratPlot.toString.split("@")(1)}"

          uger {
          
            cmd"""python $pyPhenoDistPlot
              --pheno ${Input.Local.pheno}
              --pheno-name ${phenoName}
              --fam ${paramsArr.cleanName}.fam
              --out ${reportAnalysisPhenoDistPlot}"""
              .in(paramsArr.clean :+ ancestryInferredMerged :+ Input.Local.pheno)
              .out(reportAnalysisPhenoDistPlot)
          
            cmd"""python $pyPhenoDistPlot
              --strat
              --ancestry ${ancestryInferredMerged}
              --pheno ${Input.Local.pheno}
              --pheno-name ${phenoName}
              --fam ${paramsArr.cleanName}.fam
              --out ${reportAnalysisPhenoDistStratPlot}"""
              .in(paramsArr.clean :+ ancestryInferredMerged :+ Input.Local.pheno)
              .out(reportAnalysisPhenoDistStratPlot)
          
          }

          reportAnalysisPhenoDistPlotList = reportAnalysisPhenoDistPlotList :+ reportAnalysisPhenoDistPlot
          reportAnalysisPhenoDistStratPlotList = reportAnalysisPhenoDistStratPlotList :+ reportAnalysisPhenoDistStratPlot

          for {
            m <-  modelSeq.zipWithIndex.filter(_._1._1 == phenoName).map(_._2)
          } {

            val paramsModel = paramsArr.paramsByArrByModelSorted(m)
            val modelPhenoString = Seq(paramsModel.modelPheno, paramsModel.modelTrans, paramsModel.modelCovars.replace("+","_")).filter(_ != "").mkString("_")
            reportAnalysisModelPhenoFileList = reportAnalysisModelPhenoFileList :+ paramsModel.modelPhenoFile
            reportAnalysisModelSamplesIncludeList = reportAnalysisModelSamplesIncludeList :+ paramsModel.modelSamplesInclude
            reportAnalysisModelPcsFileList = reportAnalysisModelPcsFileList :+ paramsModel.modelPcsFile
            reportAnalysisModelPhenoFileStrings = reportAnalysisModelPhenoFileStrings :+ paramsArr.arrayId + "___" + modelPhenoString + "___" + s"${paramsModel.modelPhenoFile.toString.split("@")(1)}"
            reportAnalysisModelSamplesIncludeStrings = reportAnalysisModelSamplesIncludeStrings :+ paramsArr.arrayId + "___" + modelPhenoString + "___" + s"${paramsModel.modelSamplesInclude.toString.split("@")(1)}"
            reportAnalysisModelPcsFileStrings = reportAnalysisModelPcsFileStrings :+ paramsArr.arrayId + "___" + modelPhenoString + "___" + s"${paramsModel.modelPcsFile.toString.split("@")(1)}"

          }

      }

      for {
        m <-  modelSeq.zipWithIndex.filter(_._1._1 == phenoName).map(_._2)
      } {

        val paramsResult = Params.paramsByResultSorted(m)
        val resultPhenoString = Seq(paramsResult.resultPheno, paramsResult.resultTrans, paramsResult.resultCovars.replace("+","_")).filter(_ != "").mkString("_")
        reportAnalysisModelQqPlotList = reportAnalysisModelQqPlotList :+ paramsResult.resultFinalQqPlot
        reportAnalysisModelMhtPlotList = reportAnalysisModelMhtPlotList :+ paramsResult.resultFinalMhtPlot
        reportAnalysisModelTop20AnnotAlignedRiskList = reportAnalysisModelTop20AnnotAlignedRiskList :+ paramsResult.resultFinalTop20AnnotAlignedRisk
        reportAnalysisModelQqPlotStrings = reportAnalysisModelQqPlotStrings :+ resultPhenoString + "___" + s"${paramsResult.resultFinalQqPlot.toString.split("@")(1)}"
        reportAnalysisModelMhtPlotStrings = reportAnalysisModelMhtPlotStrings :+ resultPhenoString + "___" + s"${paramsResult.resultFinalMhtPlot.toString.split("@")(1)}"
        reportAnalysisModelTop20AnnotAlignedRiskStrings = reportAnalysisModelTop20AnnotAlignedRiskStrings :+ resultPhenoString + "___" + s"${paramsResult.resultFinalTop20AnnotAlignedRisk.toString.split("@")(1)}"

        reportAnalysisModelRegplotsList = reportAnalysisModelRegplotsList ++ resultsFinalRegplots(m)
        var regPlotStrings = Seq[String]()
        for {
          p <- resultsFinalRegplots(m)
        } {

          regPlotStrings = regPlotStrings :+ s"${p.toString.split("@")(1)}"

        }

        reportAnalysisModelRegplotsStrings = { 
          if (regPlotStrings.size > 0) { reportAnalysisModelRegplotsStrings :+ resultPhenoString + "___" + regPlotStrings.mkString(";") }
          else { reportAnalysisModelRegplotsStrings }
        }

      }

      for {
        m <-  knownLociSeq.zipWithIndex.filter(_._1._1 == phenoName).map(_._2)
      } {

        val paramsResultKnownLoci = Params.paramsByResultKnownLociSorted(m)
        val resultKnownLociPhenoString = Seq(paramsResultKnownLoci.resultKnownLociPhenoName, paramsResultKnownLoci.resultKnownLociTrans, paramsResultKnownLoci.resultKnownLociCovars.replace("+","_")).filter(_ != "").mkString("_")
        reportAnalysisModelTop50KnownList = reportAnalysisModelTop50KnownList :+ paramsResultKnownLoci.resultKnownLociFinalTop50Known
        reportAnalysisModelTop50KnownStrings = reportAnalysisModelTop50KnownStrings :+ resultKnownLociPhenoString + "___" + s"${paramsResultKnownLoci.resultKnownLociFinalTop50Known.toString.split("@")(1)}"
        reportAnalysisModelTop50KnownDesc = reportAnalysisModelTop50KnownDesc :+ resultKnownLociPhenoString + "___" + s"${paramsResultKnownLoci.resultKnownLociDesc}"
        reportAnalysisModelTop50KnownTag = reportAnalysisModelTop50KnownTag :+ resultKnownLociPhenoString + "___" + s"${paramsResultKnownLoci.resultKnownLociTag}"
        reportAnalysisModelTop50KnownCitation = reportAnalysisModelTop50KnownCitation :+ s"${paramsResultKnownLoci.resultKnownLociTag}" + "___" + s"${paramsResultKnownLoci.resultKnownLociCitation}"

      }

      uger {
      
        cmd"""python $pyGenerateAnalysisReportPhenoSummary
          --dist-plot "${reportAnalysisPhenoDistPlotStrings.mkString(",")}"
          --strat-dist-plot "${reportAnalysisPhenoDistStratPlotStrings.mkString(",")}"
          --pheno-master ${Input.Local.pheno}
          --id-col $phenoId
          --sex-col $phenoSrSex
          --pheno "${reportAnalysisModelPhenoFileStrings.mkString(",")}"
          --pheno-name ${phenoName}
          --pheno-long-name "${phenoLongName}"
          --ancestry ${ancestryInferredMerged}
          --samples-include "${reportAnalysisModelSamplesIncludeStrings.mkString(",")}"
          --pcs-include "${reportAnalysisModelPcsFileStrings.mkString(",")}"
          --out-tex ${reportAnalysisPhenoSummary}
          --out-input ${reportAnalysisPhenoSummaryInput}"""
          .in(reportAnalysisModelPhenoFileList ++ reportAnalysisModelSamplesIncludeList ++ reportAnalysisModelPcsFileList ++ reportAnalysisPhenoDistPlotList ++ reportAnalysisPhenoDistStratPlotList :+ ancestryInferredMerged :+ Input.Local.pheno)
          .out(reportAnalysisPhenoSummary, reportAnalysisPhenoSummaryInput)
        
        cmd"""python $pyGenerateAnalysisReportPhenoCalibration
          --qq-plots "${reportAnalysisModelQqPlotStrings.mkString(",")}"
          --mht-plots "${reportAnalysisModelMhtPlotStrings.mkString(",")}"
          --pheno-name ${phenoName}
          --pheno-long-name "${phenoLongName}"
          --out-tex ${reportAnalysisPhenoCalibration}
          --out-input ${reportAnalysisPhenoCalibrationInput}"""
          .in(reportAnalysisModelQqPlotList ++ reportAnalysisModelMhtPlotList)
          .out(reportAnalysisPhenoCalibration, reportAnalysisPhenoCalibrationInput)
        
        cmd"""python $pyGenerateAnalysisReportPhenoTopLoci
          --top-results "${reportAnalysisModelTop20AnnotAlignedRiskStrings.mkString(",")}"
          --regionals "${reportAnalysisModelRegplotsStrings.mkString(",")}"
          --pheno-name ${phenoName}
          --pheno-long-name "${phenoLongName}"
          --out-tex ${reportAnalysisPhenoTopLoci}
          --out-input ${reportAnalysisPhenoTopLociInput}"""
          .in(reportAnalysisModelTop20AnnotAlignedRiskList ++ reportAnalysisModelRegplotsList)
          .out(reportAnalysisPhenoTopLoci, reportAnalysisPhenoTopLociInput)

        cmd"""python $pyGenerateAnalysisReportPhenoKnownLoci
          --top-known-loci "${reportAnalysisModelTop50KnownStrings.mkString(",")}"
          --pheno-name ${phenoName}
          --pheno-long-name "${phenoLongName}"
          --desc "${reportAnalysisModelTop50KnownDesc.mkString(",,,")}"
          --tag "${reportAnalysisModelTop50KnownTag.mkString(",")}"
          --out-tex ${reportAnalysisPhenoKnownLoci}
          --out-input ${reportAnalysisPhenoKnownLociInput}"""
          .in(reportAnalysisModelTop50KnownList)
          .out(reportAnalysisPhenoKnownLoci, reportAnalysisPhenoKnownLociInput)
      
      }

      reportAnalysisResultsList = reportAnalysisResultsList :+ reportAnalysisPhenoSummary :+ reportAnalysisPhenoCalibration :+ reportAnalysisPhenoTopLoci :+ reportAnalysisPhenoKnownLoci
      reportAnalysisResultsStringList = reportAnalysisResultsStringList :+ s"${reportAnalysisPhenoSummary.toString.split("@")(1)}" :+ s"${reportAnalysisPhenoCalibration.toString.split("@")(1)}" :+ s"${reportAnalysisPhenoTopLoci.toString.split("@")(1)}" :+ s"${reportAnalysisPhenoKnownLoci.toString.split("@")(1)}"
      reportAnalysisResultsInputList = reportAnalysisResultsInputList :+ reportAnalysisPhenoSummaryInput :+ reportAnalysisPhenoCalibrationInput :+ reportAnalysisPhenoTopLociInput :+ reportAnalysisPhenoKnownLociInput
      reportAnalysisResultsInputStringList = reportAnalysisResultsInputStringList :+ s"${reportAnalysisPhenoSummaryInput.toString.split("@")(1)}" :+ s"${reportAnalysisPhenoCalibrationInput.toString.split("@")(1)}" :+ s"${reportAnalysisPhenoTopLociInput.toString.split("@")(1)}" :+ s"${reportAnalysisPhenoKnownLociInput.toString.split("@")(1)}"

    }

    uger {

      cmd"""python $pyGenerateAnalysisReportBibliography
        --names "${analysisReportAcknowledgements}"
        --known-loci-citations "${reportAnalysisModelTop50KnownCitation.mkString(",,,")}"
        --out-tex ${reportAnalysisBibliography}
        --out-input ${reportAnalysisBibliographyInput}"""
        .out(reportAnalysisBibliography, reportAnalysisBibliographyInput)

      cmd"""cat ${reportAnalysisIntro} ${reportAnalysisData} ${reportAnalysisStrategy} ${reportAnalysisResultsStringList.mkString(" ")} ${reportAnalysisBibliography} > $reportAnalysisTex"""
        .in(reportAnalysisResultsList :+ reportAnalysisIntro :+ reportAnalysisData :+ reportAnalysisStrategy :+ reportAnalysisBibliography)
        .out(reportAnalysisTex)
      
      cmd"""cat ${reportAnalysisIntroInput} ${reportAnalysisDataInput} ${reportAnalysisStrategyInput} ${reportAnalysisResultsInputStringList.mkString(" ")} ${reportAnalysisBibliographyInput} > $reportAnalysisInput"""
        .in(reportAnalysisResultsInputList :+ reportAnalysisIntroInput :+ reportAnalysisDataInput :+ reportAnalysisStrategyInput :+ reportAnalysisBibliographyInput)
        .out(reportAnalysisInput)
      
      cmd"""$binPdflatex --output-directory=${localOutDir} $reportAnalysisTex; sleep 5; $binPdflatex --output-directory=${localOutDir} $reportAnalysisTex """
        .in(reportAnalysisTex)
        .out(reportAnalysisPdf)
    }

  }
}

def qc1(i: Int): Store = {

  val (_, paramsArr) = Params.paramsByArr(i)

  /**
  * Prepare Step
  *  Description: Prepare plink files by: removing lowest quality duplicate variants, etc.
  *  Requires: Plink1.9
  */
  
  uger {
  
    cmd"""awk '$$1 == 0 {print $$2}' ${paramsArr.arrayDataPath}.bim > ${paramsArr.arrayDataRawUnplaced}"""
      .in(paramsArr.arrayData)
      .out(paramsArr.arrayDataRawUnplaced)
  
    cmd"""awk '{k=$$1":"$$4":"$$5":"$$6; if(!m[k]) {print $$2; m[k]=1}}' ${paramsArr.arrayDataPath}.bim > ${paramsArr.arrayDataRawUnique}"""
      .in(paramsArr.arrayData)
      .out(paramsArr.arrayDataRawUnique)
  
    cmd"""awk '{if($$5$$6 == "ID" || $$5$$6 == "DI") print $$2}' ${paramsArr.arrayDataPath}.bim > ${paramsArr.arrayDataRawIndel}"""
      .in(paramsArr.arrayData)
      .out(paramsArr.arrayDataRawIndel)
  
    cmd"""$binPlink --bfile ${paramsArr.arrayDataPath} --missing --out ${paramsArr.arrayDataRawName}.missing"""
      .in(paramsArr.arrayData)
      .out(paramsArr.arrayDataRawLmiss)
  
    cmd"""$binPlink --bfile ${paramsArr.arrayDataPath} --freq --out ${paramsArr.arrayDataRawName}.freq"""
      .in(paramsArr.arrayData)
     .out(paramsArr.arrayDataRawFreq)
  
    cmd"""sed '1d' ${paramsArr.arrayDataRawFreq} | awk '{if($$5 == 0) print $$2}' > ${paramsArr.arrayDataRawMono}"""
      .in(paramsArr.arrayDataRawFreq)
      .out(paramsArr.arrayDataRawMono)
  
    // run find_best_duplicate_variants.r to generate exclude list for duplicates
    cmd"""$binRscript --vanilla --verbose 
      $rFindBestDuplicateVariants
      --bim-in ${paramsArr.arrayDataPath}.bim
      --freq-in ${paramsArr.arrayDataRawFreq}
      --miss-in ${paramsArr.arrayDataRawLmiss}
      --out ${paramsArr.arrayDataRawDupRemove}"""
      .in(paramsArr.arrayData, paramsArr.arrayDataRawFreq, paramsArr.arrayDataRawLmiss)
      .out(paramsArr.arrayDataRawDupRemove)
  
    cmd"""$binPlink --bfile ${paramsArr.arrayDataPath} --exclude ${paramsArr.arrayDataRawDupRemove} --make-bed --out ${paramsArr.arrayDataPreparedName}"""
      .in(paramsArr.arrayData, paramsArr.arrayDataRawDupRemove)
      .out(paramsArr.arrayDataPrepared)
  
    cmd"""awk '{if(x[$$1":"$$4]) {x_count[$$1":"$$4]++; print $$2; if(x_count[$$1":"$$4] == 1) {print x[$$1":"$$4]}} x[$$1":"$$4] = $$2}' ${paramsArr.arrayDataPreparedName}.bim > ${paramsArr.arrayDataPreparedMultiallelic}"""
      .in(paramsArr.arrayDataPrepared)
      .out(paramsArr.arrayDataPreparedMultiallelic)
  
  }  
  
  /**
  * Harmonize Step
  *  Description: Align data strand to 1KG reference. Also, update reference allele and variant ID to match 1KG
  *  Requires: Plink1.9 and, at least, Genotype Harmonizer v1.4.18
  *  Notes:
  *     Could also add --variants and --mafAlign as pipeline options, but for now these are static
  *     To save time, this will be run in parallel by chromosome number
  */
  
  for {
    (chr, paramsChr) <- paramsArr.paramsByArrByChr
  } {

    uger {

	  cmd"""$binPlink --bfile ${paramsArr.arrayDataPreparedName} --chr $chr --keep-allele-order --make-bed --output-chr MT --out ${paramsChr.rawChrName} --memory 3000 --threads 1"""
        .in(paramsArr.arrayDataPrepared)
        .out(paramsChr.rawChr)
    
      cmd"""$binGenotypeHarmonizer
      --input ${paramsChr.rawChrName}
      --inputType PLINK_BED
      --output ${paramsChr.harmKgChrName}
      --outputType PLINK_BED
      --ref ${paramsChr.kgVcfChr}
      --refType VCF
      --keep
      --update-id
      --variants 1000
      --mafAlign 0.1
      --update-id
      --update-reference-allele
      --debug"""
        .in(paramsChr.rawChr :+ paramsChr.kgVcfChr)
        .out(paramsChr.harmKgChr :+ paramsChr.harmKgChrVarIdUpdate :+ paramsChr.harmKgChrVarSnpLog)
      
      cmd"""python $pyAlignNon1kgVariants
      --legend ${paramsChr.kgLegendChr}
      --bim ${paramsChr.harmKgChrName}.bim
      --ref ${paramsChr.humanReference}
      --out-remove ${paramsChr.harmNonKgChrRemove}
      --out-ignore ${paramsChr.harmNonKgChrIgnore}
      --out-mono ${paramsChr.harmNonKgChrMono}
      --out-nomatch ${paramsChr.harmNonKgChrNomatch}
      --out-flip ${paramsChr.harmNonKgChrFlip}
      --out-force-a1 ${paramsChr.harmNonKgChrForceA1}"""
        .in(paramsChr.harmKgChr :+ paramsChr.kgLegendChr)
        .out(paramsChr.harmNonKgChrRemove, paramsChr.harmNonKgChrIgnore, paramsChr.harmNonKgChrMono,paramsChr.harmNonKgChrNomatch, paramsChr.harmNonKgChrFlip, paramsChr.harmNonKgChrForceA1)
      
      cmd"""$binPlink --bfile ${paramsChr.harmKgChrName} --exclude ${paramsChr.harmNonKgChrRemove} --flip ${paramsChr.harmNonKgChrFlip} --a1-allele ${paramsChr.harmNonKgChrForceA1} --make-bed --out ${paramsChr.harmKgHuRefChrName} --memory 3000 --threads 1"""
        .in(paramsChr.harmKgChr :+ paramsChr.harmNonKgChrRemove :+ paramsChr.harmNonKgChrFlip :+ paramsChr.harmNonKgChrForceA1)
        .out(paramsChr.harmKgHuRefChr)

    }
  
  }
  
  val harmMergeLinesConcat: String = paramsArr.harmMergeLines
    .drop(1)
    .mkString("\n") // Exclude first chrom

  local {

    cmd"""echo "$harmMergeLinesConcat" > ${paramsArr.harmMergeList}"""
      .out(paramsArr.harmMergeList)

  }

  uger {
  
    cmd"""$binPlink --bfile ${paramsArr.paramsByArrByChrSorted.head.harmKgHuRefChrName} --merge-list ${paramsArr.harmMergeList} --make-bed --keep-allele-order --out ${paramsArr.harmName} --memory 3000 --threads 1"""
      .in(paramsArr.paramsByArrByChrSorted.flatMap(_.harmKgHuRefChr) :+ paramsArr.harmMergeList)
      .out(paramsArr.harm)

  }

  local {
  
    cmd"""awk '{print $$2,$$5}' ${paramsArr.harmName}.bim > ${paramsArr.harmForceA2}"""
      .in(paramsArr.harm)
      .out(paramsArr.harmForceA2)

  }

  uger {
  
    cmd"""$binPlink --bfile ${paramsArr.harmName} --real-ref-alleles --a2-allele ${paramsArr.harmForceA2} --make-bed --out ${paramsArr.harmRefName} --memory 3000 --threads 1"""
      .in(paramsArr.harm :+ paramsArr.harmForceA2)
      .out(paramsArr.harmRef)
    
    cmd"""$binPlink --bfile ${paramsArr.harmName} --recode vcf-iid bgz --real-ref-alleles --a2-allele ${paramsArr.harmForceA2} --out ${paramsArr.harmRefName} --memory 3000 --threads 1"""
      .in(paramsArr.harm :+ paramsArr.harmForceA2)
      .out(paramsArr.harmRefVcf)
    
    cmd"""$binTabix -f -p vcf ${paramsArr.harmRefVcf}"""
      .in(paramsArr.harmRefVcf)
      .out(paramsArr.harmRefVcfTbi)

  }
  
  val harmNonKgChrRemoveString = paramsArr.paramsByArrByChrSorted.map{ e => s"""${e.harmNonKgChrRemove.toString.split("@")(1)}"""}.mkString(",")
  val harmNonKgChrMonoString = paramsArr.paramsByArrByChrSorted.map{ e => s"""${e.harmNonKgChrMono.toString.split("@")(1)}"""}.mkString(",")
  val harmNonKgChrNomatchString = paramsArr.paramsByArrByChrSorted.map{ e => s"""${e.harmNonKgChrNomatch.toString.split("@")(1)}"""}.mkString(",")
  val harmNonKgChrIgnoreString = paramsArr.paramsByArrByChrSorted.map{ e => s"""${e.harmNonKgChrIgnore.toString.split("@")(1)}"""}.mkString(",")
  val harmNonKgChrFlipString = paramsArr.paramsByArrByChrSorted.map{ e => s"""${e.harmNonKgChrFlip.toString.split("@")(1)}"""}.mkString(",")
  val harmNonKgChrForceA1String = paramsArr.paramsByArrByChrSorted.map{ e => s"""${e.harmNonKgChrForceA1.toString.split("@")(1)}"""}.mkString(",")
  val harmKgChrVarSnpLogString = paramsArr.paramsByArrByChrSorted.map{ e => s"""${e.harmKgChrVarSnpLog.toString.split("@")(1)}"""}.mkString(",")

  ugerWith(mem=8) {

    cmd"""python $pyMergeVariantLists
      --remove-in "$harmNonKgChrRemoveString"
      --remove-mono-in "$harmNonKgChrMonoString"
      --remove-nomatch-in "$harmNonKgChrNomatchString"
      --ignore-in "$harmNonKgChrIgnoreString"
      --flip-in "$harmNonKgChrFlipString"
      --force-a1-in "$harmNonKgChrForceA1String"
      --snp-log-in "$harmKgChrVarSnpLogString"
      --remove-out ${paramsArr.harmNonKgRemove}
      --remove-mono-out ${paramsArr.harmNonKgMono}
      --remove-nomatch-out ${paramsArr.harmNonKgNomatch}
      --ignore-out ${paramsArr.harmNonKgIgnore}
      --flip-out ${paramsArr.harmNonKgFlip}
      --force-a1-out ${paramsArr.harmNonKgForceA1}
      --snp-log-out ${paramsArr.harmKgVarSnpLog}
      """
      .in(paramsArr.paramsByArrByChrSorted.map(_.harmNonKgChrRemove) ++ paramsArr.paramsByArrByChrSorted.map(_.harmNonKgChrMono) ++ paramsArr.paramsByArrByChrSorted.map(_.harmNonKgChrNomatch) ++ paramsArr.paramsByArrByChrSorted.map(_.harmNonKgChrIgnore) ++ paramsArr.paramsByArrByChrSorted.map(_.harmNonKgChrFlip) ++ paramsArr.paramsByArrByChrSorted.map(_.harmNonKgChrForceA1) ++ paramsArr.paramsByArrByChrSorted.map(_.harmKgChrVarSnpLog))
      .out(paramsArr.harmNonKgRemove, paramsArr.harmNonKgNomatch, paramsArr.harmNonKgMono, paramsArr.harmNonKgIgnore, paramsArr.harmNonKgFlip, paramsArr.harmNonKgForceA1, paramsArr.harmKgVarSnpLog)

  }
  
  /**
   * Load Step
   *  Description: Generate the Hail VDS from VCF file and a sample file containing population and sex information
   *  Requires: Hail
   */
  
  local {

    googleCopy(paramsArr.harmRefVcf, paramsArr.harmRefVcfCloud)
    googleCopy(paramsArr.harmRefVcfTbi, paramsArr.harmRefVcfTbiCloud)

  }
  
  google {

    hail"""$pyHailLoad
      --vcf-in $projectId ${paramsArr.harmRefVcfCloud}
      --vds-out ${paramsArr.harmRefVdsCloud}"""
      .in(paramsArr.harmRefVcfCloud, paramsArr.harmRefVcfTbiCloud)
      .out(paramsArr.harmRefVdsCloud)

  }
  
  /**
   * Filter Step
   *  Description: Generate filtered and filtered/pruned filesets for QC
   *  Requires: Hail
   */
  
  google {

    hail"""$pyHailFilter
      --vds-in ${paramsArr.harmRefVdsCloud}
      --regions-exclude ${Input.Google.regionsExclude}
      --variant-qc-out ${paramsArr.harmRefFiltVariantQcCloud}
      --variants-prunedin-out ${paramsArr.harmRefFiltVariantsPrunedInCloud}
      --filt-vds-out ${paramsArr.harmRefFiltVdsCloud}
      --filt-plink-out ${paramsArr.harmRefFiltNameCloud}
      --filt-pruned-vds-out ${paramsArr.harmRefFiltPrunedVdsCloud}
      --filt-pruned-plink-out ${paramsArr.harmRefFiltPrunedNameCloud}"""
      .in(paramsArr.harmRefVdsCloud, Input.Google.regionsExclude)
      .out(((paramsArr.harmRefFiltCloud :+ paramsArr.harmRefFiltVdsCloud) ++ (paramsArr.harmRefFiltPrunedCloud :+ paramsArr.harmRefFiltPrunedVdsCloud)) :+ paramsArr.harmRefFiltVariantQcCloud :+ paramsArr.harmRefFiltVariantsPrunedInCloud)

  }
  
  local {

    googleCopy(paramsArr.harmRefFiltPrunedCloud, paramsArr.harmRefFiltPruned)

  }
  
  /**
   * Kinship Step
   *  Description: Calculate kinship to identify duplicates and any samples exhibiting abnormal (excessive) sharing
   *  Requires: King, R
   *  Notes:
   *     King is preferred to Plink or Hail based IBD calcs due to robust algorithm handling of population stratification. This step should be followed by a visual inspection for duplicates or excessive sharing
   * King only writes the '.kin0' file if families are found, so a bash script is used to write an empty file in that case
   */
  
  ugerWith(cores=4, mem=4) {

    cmd"""$shKing $binKing ${paramsArr.harmRefFiltPrunedName}.bed ${paramsArr.kinName} ${paramsArr.kinLog} ${paramsArr.kinKin0} ${paramsArr.kinKin0Related} 4"""
    .in(paramsArr.harmRefFiltPruned)
    .out(paramsArr.kinLog, paramsArr.kinKin, paramsArr.kinTmpDat, paramsArr.kinTmpPed, paramsArr.kinKin0, paramsArr.kinKin0Related)

  }

  uger {

    cmd"""$binR --vanilla --args ${paramsArr.kinKin0Related} ${paramsArr.kinFamsizes} < ${rCalcKinshipFamSizes}"""
    .in(paramsArr.kinKin0Related)
    .out(paramsArr.kinFamsizes)

  }
  
  /**
    * Ancestry PCA Step
    *  Description: Calculate PCs combined with 1KG Phase 3 Purcell 5k data
    *  Requires: Hail, R, $rPlotAncestryPca
    *  Notes:
    *     To perform ancestry inference and clustering with 1KG data, we must combine on common variants with reference data (clustering does not work when only using PCA loadings and projecting)
    */
  
  google {

    hail"""$pyHailAncestryPcaMerge1kg
      --vds-in ${paramsArr.harmRefVdsCloud}
      --kg-vcf-in ${Input.Google.kgPurcellVcf}
      --kg-sample ${Input.Google.kgSample}
      --plink-out ${paramsArr.harmRef1kgNameCloud}"""
      .in(paramsArr.harmRefVdsCloud, Input.Google.kgPurcellVcf, Input.Google.kgSample)
      .out(paramsArr.harmRef1kgCloud)

  }
  
  local {

    googleCopy(paramsArr.harmRef1kgCloud, paramsArr.harmRef1kg)

  }
  
  ugerWith(cores=4, mem=4) {

    cmd"""$binRscript --vanilla --verbose
      $rPcair
      --cpus 4
      --plink-in ${paramsArr.harmRef1kgName}
      --gds-out ${paramsArr.harmRef1kgGds}
      --scores ${paramsArr.ancestryPcaScores}
      --id $projectId
      --force-unrel $kgSampleId ${Input.Local.kgSample}
      --update-pop $kgSampleId $kgSamplePop ${Input.Local.kgSample}
      --update-group $kgSampleId $kgSampleGroup ${Input.Local.kgSample}
      > ${paramsArr.ancestryPcaLog}"""
      .in(paramsArr.harmRef1kg :+ Input.Local.kgSample)
      .out(paramsArr.harmRef1kgGds, paramsArr.ancestryPcaLog, paramsArr.ancestryPcaScores)
      .using("R-3.4")

  }

  uger {

    cmd"""$binR --vanilla --args $projectId ${paramsArr.ancestryPcaScores} ${paramsArr.ancestryPcaScoresPlots} < $rPlotAncestryPca"""
    .in(paramsArr.ancestryPcaScores)
    .out(paramsArr.ancestryPcaScoresPlots)
    
    cmd"""$binConvert -density 300 -depth 8 -quality 100 -flatten ${paramsArr.ancestryPcaScoresPlots}[0] ${paramsArr.ancestryPcaScoresPlotPc1VsPc2}"""
      .in(paramsArr.ancestryPcaScoresPlots)
      .out(paramsArr.ancestryPcaScoresPlotPc1VsPc2)
    
    cmd"""$binConvert -density 300 -depth 8 -quality 100 -flatten ${paramsArr.ancestryPcaScoresPlots}[1] ${paramsArr.ancestryPcaScoresPlotPc2VsPc3}"""
      .in(paramsArr.ancestryPcaScoresPlots)
      .out(paramsArr.ancestryPcaScoresPlotPc2VsPc3)

  }
  
  /**
   * Ancestry Cluster Step
   *  Description: Cluster with 1KG samples using Gaussian Mixture Modeling and infer ancestry
   *  Requires: Hail, R
   *  Notes:
   *     *.ancestry.inferred.tsv contains the final inferred ancestry for each sample, including OUTLIERS
   *     This file is array specific
   */
  
  uger {

    cmd"""(echo 3; sed '1d' ${paramsArr.ancestryPcaScores} | cut -f4-6 | sed 's/\t/ /g') > ${paramsArr.ancestryClusterFet}"""
    .in(paramsArr.ancestryPcaScores)
    .out(paramsArr.ancestryClusterFet)
  
    cmd"""$binKlustakwik ${paramsArr.ancestryClusterName} 1 -UseFeatures 111 -UseDistributional 0 > ${paramsArr.ancestryClusterLog}"""
    .in(paramsArr.ancestryClusterFet)
    .out(paramsArr.ancestryClusterClu, paramsArr.ancestryClusterKlg, paramsArr.ancestryClusterLog)

  }

  uger {
  
    cmd"""$binR --vanilla --args ${paramsArr.ancestryPcaScores} ${paramsArr.ancestryClusterClu} ${Input.Local.pheno} $projectId $phenoId $phenoSrRace
      ${paramsArr.ancestryClusterPlots} ${paramsArr.ancestryClusterXtabs} ${paramsArr.ancestryClusterPlotsCenters}
      ${paramsArr.ancestryClusterGroups} ${paramsArr.ancestryInferred}
      ${paramsArr.ancestryClusterPlotsNo1kg} < $rPlotAncestryCluster"""
      .in(paramsArr.ancestryPcaScores, paramsArr.ancestryClusterClu, Input.Local.pheno)
      .out(paramsArr.ancestryClusterPlots, paramsArr.ancestryClusterXtabs, paramsArr.ancestryClusterPlotsCenters, paramsArr.ancestryClusterGroups, paramsArr.ancestryInferred, paramsArr.ancestryClusterPlotsNo1kg)
  
    cmd"""$binConvert -density 300 -depth 8 -quality 100 -flatten ${paramsArr.ancestryClusterPlots}[0] ${paramsArr.ancestryClusterPlotPc1VsPc2}"""
      .in(paramsArr.ancestryClusterPlots)
      .out(paramsArr.ancestryClusterPlotPc1VsPc2)
  
    cmd"""$binConvert -density 300 -depth 8 -quality 100 -flatten ${paramsArr.ancestryClusterPlots}[1] ${paramsArr.ancestryClusterPlotPc2VsPc3}"""
      .in(paramsArr.ancestryClusterPlots)
      .out(paramsArr.ancestryClusterPlotPc2VsPc3)
  
  }

  paramsArr.ancestryInferred

}

def qc2(i: Int): Map[(String, String, String, String, String), Store] = {

  val (_, paramsArr) = Params.paramsByArr(i)
  var resultsMap = Seq[Map[(String, String, String, String, String), Store]]()
  var knownLociMap = Seq[Map[(String, String, String, String, String, String), Store]]()

  /**
   * PCA Step
   *  Description: Calculate PCs for all non-outlier samples combined (to be used for adjustment during sample outlier removal)
   *  Requires: R
   */
  
  ugerWith(cores=4, mem=4) {
  
    cmd"""$binRscript --vanilla --verbose
      $rPcair
      --cpus 4
      --plink-in ${paramsArr.harmRefFiltPrunedName}
      --gds-out ${paramsArr.harmRefFiltPrunedPcaGds}
      --exclude ${ancestryInferredMergedOutliers}
      --ancestry ${ancestryInferredMerged}
      --id $projectId
      --scores ${paramsArr.pcaScores}
      > ${paramsArr.pcaLog}"""
      .in(paramsArr.harmRefFiltPruned :+ ancestryInferredMerged :+ ancestryInferredMergedOutliers)
      .out(paramsArr.harmRefFiltPrunedPcaGds, paramsArr.pcaLog, paramsArr.pcaScores)
      .using("R-3.4")

  }
  
  /**
   * Sample QC Stats Calculation Step
   *  Description: Calculate sexcheck and sample by variant statistics for all samples
   *  Requires: Hail, R
   */
  
  local {

    googleCopy(ancestryInferredMerged, ancestryInferredMergedCloud)
    googleCopy(Input.Local.pheno, Input.Google.pheno)

  }
  
  google {

    hail"""$pyHailSexcheck
      --vds-in ${paramsArr.harmRefVdsCloud}
      --regions-exclude ${Input.Google.regionsExclude}
      --pheno-in ${Input.Google.pheno}
      --id-col $phenoId
      --sex-col $phenoSrSex
      --sexcheck-out ${paramsArr.sampleqcSexcheckCloud}
      --sexcheck-problems-out ${paramsArr.sampleqcSexcheckProblemsCloud}"""
      .in(Input.Google.pheno, paramsArr.harmRefVdsCloud, Input.Google.regionsExclude)
      .out(paramsArr.sampleqcSexcheckCloud, paramsArr.sampleqcSexcheckProblemsCloud)
  
    hail"""$pyHailSampleqc
      --vds-in ${paramsArr.harmRefFiltPrunedVdsCloud}
      --clusters-in ${ancestryInferredMergedCloud}
      --qc-out ${paramsArr.sampleqcStatsCloud}"""
      .in(paramsArr.harmRefFiltPrunedVdsCloud, ancestryInferredMergedCloud)
      .out(paramsArr.sampleqcStatsCloud)

  }
  
  local {

    googleCopy(paramsArr.sampleqcStatsCloud, paramsArr.sampleqcStats)

  }
  
  uger {

    cmd"""$binR --vanilla --args ${paramsArr.sampleqcStats} ${paramsArr.pcaScores} ${paramsArr.sampleqcStatsAdj} < $rCalcIstatsAdj"""
    .in(paramsArr.sampleqcStats, paramsArr.pcaScores)
    .out(paramsArr.sampleqcStatsAdj)
  
    cmd"""$binR --vanilla --args ${paramsArr.sampleqcStatsAdj} ${paramsArr.sampleqcStatsAdjCorrPlots} ${paramsArr.sampleqcStatsAdjPcaLoadings} ${paramsArr.sampleqcStatsAdjPcaScoresPlots} ${paramsArr.sampleqcStatsAdjPcaScores} < $rIstatsAdjPca"""
    .in(paramsArr.sampleqcStatsAdj)
    .out(paramsArr.sampleqcStatsAdjCorrPlots, paramsArr.sampleqcStatsAdjPcaLoadings, paramsArr.sampleqcStatsAdjPcaScoresPlots, paramsArr.sampleqcStatsAdjPcaScores)

  }
  
  local {

    googleCopy(paramsArr.sampleqcSexcheckCloud, paramsArr.sampleqcSexcheck)
    googleCopy(paramsArr.sampleqcSexcheckProblemsCloud, paramsArr.sampleqcSexcheckProblems)

  }
  
  /**
   * Sample QC PCA Clustering Step
   *  Description: Cluster PCs of adjusted sample QC metrics
   *  Requires: Klustakwik, R
   */
  
  uger {

    cmd"""N=$$(head -1 ${paramsArr.sampleqcStatsAdjPcaScores} | wc | awk '{print $$2-1}');
      echo $$N > ${paramsArr.sampleqcStatsAdjClusterFet};
      sed '1d' ${paramsArr.sampleqcStatsAdjPcaScores} | cut -f2- | sed 's/\t/ /g' >> ${paramsArr.sampleqcStatsAdjClusterFet};
      FEATURES=1; for i in $$(seq 2 $$N); do FEATURES=$${FEATURES}1; done;
      $binKlustakwik ${paramsArr.sampleqcStatsAdjClusterName} 1 -UseFeatures $$FEATURES -UseDistributional 0 >
      ${paramsArr.sampleqcStatsAdjClusterKlustakwikLog}"""
      .in(paramsArr.sampleqcStatsAdjPcaScores)
      .out(paramsArr.sampleqcStatsAdjClusterFet, paramsArr.sampleqcStatsAdjClusterClu, paramsArr.sampleqcStatsAdjClusterKlg, paramsArr.sampleqcStatsAdjClusterKlustakwikLog)

    cmd"""$binR --vanilla --args ${paramsArr.sampleqcStatsAdjPcaScores} ${paramsArr.sampleqcStatsAdjClusterClu}
      ${paramsArr.sampleqcStatsAdjClusterOutliers} ${paramsArr.sampleqcStatsAdjClusterPlots}
      ${paramsArr.sampleqcStatsAdjClusterXtabs} $projectId < $rIstatsPcsGmmClusterPlot"""
      .in(paramsArr.sampleqcStatsAdjPcaScores, paramsArr.sampleqcStatsAdjClusterClu)
      .out(paramsArr.sampleqcStatsAdjClusterOutliers, paramsArr.sampleqcStatsAdjClusterPlots, paramsArr.sampleqcStatsAdjClusterXtabs)
  
  }
  
  /**
   * Sample QC Individual Stats Clustering Step
   *  Description: Cluster PCs of adjusted sample QC metrics
   *  Requires: Klustakwik, R
   */
  
  var sampleqcIndCluFiles = Seq[String]()

  for {
    (metric, paramsMetric) <- paramsArr.paramsByArrByMetric
    } {

      sampleqcIndCluFiles = sampleqcIndCluFiles :+ paramsMetric.sampleqcStatsAdjIndMetric + "___" + s"${paramsMetric.sampleqcStatsAdjIndClusterClu.toString.split("@")(1)}"
  
    uger {

      cmd"""echo 1 > ${paramsMetric.sampleqcStatsAdjIndClusterFet};
        metricIdx=`head -1 ${paramsArr.sampleqcStatsAdj} | tr '\t' '\n' | awk '{print NR" "$$0}' | grep -w ${paramsMetric.sampleqcStatsAdjIndMetric} | awk '{print $$1}'`;
        sed '1d' ${paramsArr.sampleqcStatsAdj} | awk -v col=$${metricIdx} '{print $$col}' >> ${paramsMetric.sampleqcStatsAdjIndClusterFet}"""
        .in(paramsArr.sampleqcStatsAdj)
        .out(paramsMetric.sampleqcStatsAdjIndClusterFet)

      cmd"""$binKlustakwik ${paramsMetric.sampleqcStatsAdjIndClusterName} 1 -UseFeatures 1 -UseDistributional 0 > ${paramsMetric.sampleqcStatsAdjIndClusterKlustakwikLog}"""
        .in(paramsMetric.sampleqcStatsAdjIndClusterFet)
        .out(paramsMetric.sampleqcStatsAdjIndClusterClu, paramsMetric.sampleqcStatsAdjIndClusterKlg, paramsMetric.sampleqcStatsAdjIndClusterKlustakwikLog)

    }
  
  }
  
  uger {

    cmd"""$binR --vanilla --args
      ${sampleQcMetrics.mkString(",")}
      ${paramsArr.sampleqcStats}
      ${paramsArr.sampleqcStatsAdj}
      ${paramsArr.sampleqcStatsAdjClusterOutliers}
      ${paramsArr.sampleqcStatsAdjIndBoxplots}
      ${paramsArr.sampleqcStatsAdjIndDiscreteness}
      ${paramsArr.sampleqcStatsAdjOutliersTable}
      ${paramsArr.sampleqcStatsAdjStripchart}
      ${ancestryInferredMerged}
      < $rIstatsAdjGmmPlotMetrics"""
      .in(paramsArr.paramsByArrByMetricSorted.map(_.sampleqcStatsAdjIndClusterClu) :+ paramsArr.sampleqcStats :+ paramsArr.sampleqcStatsAdj :+ ancestryInferredMerged :+ paramsArr.sampleqcStatsAdjClusterOutliers)
      .out(paramsArr.sampleqcStatsAdjIndBoxplots, paramsArr.sampleqcStatsAdjIndDiscreteness, paramsArr.sampleqcStatsAdjOutliersTable, paramsArr.sampleqcStatsAdjStripchart)
  
    cmd"""$binRscript --vanilla --verbose
      $rMakeSampleqcOutlierPlot
      --ind-clu-files "${sampleqcIndCluFiles.mkString(",")}"
      --stats-unadj ${paramsArr.sampleqcStats}
      --stats-adj ${paramsArr.sampleqcStatsAdj}
      --metric-pca-outliers ${paramsArr.sampleqcStatsAdjClusterOutliers}
      --out ${paramsArr.sampleqcOutlierPlotPdf}"""
      .in(paramsArr.paramsByArrByMetricSorted.map(_.sampleqcStatsAdjIndClusterClu) :+ paramsArr.sampleqcStats :+ paramsArr.sampleqcStatsAdj)
      .out(paramsArr.sampleqcOutlierPlotPdf)
      .using("R-3.4")
  
    cmd"""$binConvert -density 300 -depth 8 -quality 100 -flatten ${paramsArr.sampleqcOutlierPlotPdf}[0] ${paramsArr.sampleqcOutlierPlotPng}"""
      .in(paramsArr.sampleqcOutlierPlotPdf)
      .out(paramsArr.sampleqcOutlierPlotPng)
  
  }
  
  /**
   * Compile Sample Exclusions Step
   * Requires: Python
   */
  
  uger {
  
    cmd"""python $pyCompileExclusions
      --ancestry-inferred ${ancestryInferredMerged}
      --kinship-related ${paramsArr.kinKin0Related}
      --kinship-famsizes ${paramsArr.kinFamsizes}
      --sampleqc-outliers ${paramsArr.sampleqcStatsAdjOutliersTable}
      --sexcheck-problems ${paramsArr.sampleqcSexcheckProblems}
      --ancestry-keep ${ancestryOutliersKeep.mkString(",")}
      --duplicates-keep ${duplicatesKeep.mkString(",")}
      --famsize-keep ${famsizeKeep.mkString(",")}
      --sampleqc-keep ${sampleqcKeep.mkString(",")}
      --sexcheck-keep ${sexcheckKeep.mkString(",")}
      --out ${paramsArr.finalSampleExclusions}"""
      .in(ancestryInferredMerged, paramsArr.kinKin0Related, paramsArr.kinFamsizes, paramsArr.sampleqcStatsAdjOutliersTable, paramsArr.sampleqcSexcheckProblems)
      .out(paramsArr.finalSampleExclusions)

  }
  
  /**
  * Filter Clean Step
  * filter variants and generate final clean dataset
  */
  
  local {

    googleCopy(paramsArr.finalSampleExclusions, paramsArr.finalSampleExclusionsCloud)

  }
  
  google {

    hail"""$pyHailFilterFinal
      --vds-in ${paramsArr.harmRefVdsCloud}
      --ancestry-in ${ancestryInferredMergedCloud}
      --sexcheck-in ${paramsArr.sampleqcSexcheckCloud}
      --pheno-in ${Input.Google.pheno}
      --iid-col $phenoId
      --case-ctrl-col $phenoStatus
      --samples-remove ${paramsArr.finalSampleExclusionsCloud}
      --variantqc-out ${paramsArr.variantqcStatsCloud}
      --variants-exclude-out ${paramsArr.finalVariantExclusionsCloud}
      --plink-out ${paramsArr.cleanNameCloud}
      --vcf-out ${paramsArr.cleanVcfCloud}
      --vds-out ${paramsArr.cleanVdsCloud}"""
      .in(paramsArr.harmRefVdsCloud, ancestryInferredMergedCloud, paramsArr.sampleqcSexcheckCloud, Input.Google.pheno, paramsArr.finalSampleExclusionsCloud)
      .out(paramsArr.cleanCloud :+ paramsArr.cleanVcfCloud :+ paramsArr.variantqcStatsCloud :+ paramsArr.finalVariantExclusionsCloud :+ paramsArr.cleanVdsCloud)

  }
  
  local {

    googleCopy(paramsArr.cleanCloud, paramsArr.clean)
    googleCopy(paramsArr.cleanVcfCloud, paramsArr.cleanVcf)
    googleCopy(paramsArr.variantqcStatsCloud, paramsArr.variantqcStats)
    googleCopy(paramsArr.finalVariantExclusionsCloud, paramsArr.finalVariantExclusions)

  }
  
  local {

    cmd"""$binTabix -f -p vcf ${paramsArr.cleanVcf}"""
      .in(paramsArr.cleanVcf)
      .out(paramsArr.cleanVcfTbi)

  }
  
  ugerWith(cores=4, mem=4) {
  
    cmd"""$binRscript --vanilla --verbose
      $rPcair
      --cpus 4
      --plink-in ${paramsArr.harmRefFiltPrunedName}
      --gds-out ${paramsArr.cleanGds}
      --exclude ${paramsArr.finalSampleExclusions}
      --scores ${paramsArr.cleanPcaScores}
      > ${paramsArr.cleanPcaLog}"""
      .in(paramsArr.harmRefFiltPruned)
      .out(paramsArr.cleanGds, paramsArr.cleanPcaScores, paramsArr.cleanPcaLog)
      .using("R-3.4")
  
  }
  
  /**
   * Association Step
   *  Description: Run association tests
   *  Requires: Hail
   */
  
  for {
    (model, paramsModel) <- paramsArr.paramsByArrByModel
  } {
  
    google {

      hail"""$pyHailListSamples
        --vds-in ${paramsArr.cleanVdsCloud}
        --bim-in ${paramsArr.harmRefFiltPrunedNameCloud}.bim
        --pheno-in ${Input.Google.pheno}
        --iid-col $phenoId
        --pheno-col ${paramsModel.modelPheno}
        --test ${paramsModel.modelTest}
        --covars "${paramsModel.modelCovars}"
        --out-pheno-prelim ${paramsModel.modelPhenoPrelimFileCloud}
        --out-samples ${paramsModel.modelSamplesIncludeCloud}"""
      .in(paramsArr.harmRefFiltPrunedCloud :+ paramsArr.cleanVdsCloud :+ Input.Google.pheno)
      .out(paramsModel.modelPhenoPrelimFileCloud, paramsModel.modelSamplesIncludeCloud)

    }
    
    local {

      googleCopy(paramsModel.modelPhenoPrelimFileCloud, paramsModel.modelPhenoPrelimFile)
      googleCopy(paramsModel.modelSamplesIncludeCloud, paramsModel.modelSamplesInclude)

    }
    
    uger {

      cmd"""$binRscript --vanilla --verbose
        $rGeneratePheno
        --gds-in ${paramsArr.harmRefFiltPrunedPcaGds}
        --pheno-in ${Input.Local.pheno}
        --ancestry-in ${ancestryInferredMerged}
        --ancestry-keep "${paramsModel.modelAncestryKeep}"
        --pheno-col ${paramsModel.modelPheno}
        --iid-col $phenoId
        --samples-include ${paramsModel.modelSamplesInclude}
        --variants-exclude ID ${paramsArr.finalVariantExclusions}
        --test ${paramsModel.modelTest}
        --trans "${paramsModel.modelTrans}"
        --covars "${paramsModel.modelCovars}"
        --out-pheno ${paramsModel.modelPhenoFile}
        --out-pcs ${paramsModel.modelPcsFile}
        > ${paramsModel.modelPhenoFileLog}"""
        .in(paramsArr.harmRefFiltPrunedPcaGds, Input.Local.pheno, ancestryInferredMerged, paramsModel.modelSamplesInclude, paramsArr.finalVariantExclusions)
        .out(paramsModel.modelPhenoFile, paramsModel.modelPcsFile, paramsModel.modelPhenoFileLog)
        .using("R-3.4")

    }
    
    local {

      googleCopy(paramsModel.modelPhenoFile, paramsModel.modelPhenoFileCloud)
      googleCopy(paramsModel.modelPcsFile, paramsModel.modelPcsFileCloud)

    }
    
    google {

      hail"""$pyHailAssoc
        --vds-in ${paramsArr.cleanVdsCloud}
        --bim-in ${paramsArr.harmRefFiltPrunedNameCloud}.bim
        --pheno-in ${paramsModel.modelPhenoFileCloud}
        --iid-col $phenoId
        --pheno-col ${paramsModel.modelPheno}
        --pcs-include ${paramsModel.modelPcsFileCloud}
        --test ${paramsModel.modelTest}
        --trans "${paramsModel.modelTrans}"
        --covars "${paramsModel.modelCovars}"
        --out ${paramsModel.modelResultsCloud}"""
          .in(paramsArr.harmRefFiltPrunedCloud :+ paramsArr.cleanVdsCloud :+ Input.Google.pheno :+ paramsModel.modelPhenoFileCloud)
          .out(paramsModel.modelResultsCloud)
    
    }
    
    local {

      googleCopy(paramsModel.modelResultsCloud, paramsModel.modelResults)

    }
    
    local {

      cmd"""$binTabix -b 2 -e 2 ${paramsModel.modelResults}"""
        .in(paramsModel.modelResults)
        .out(paramsModel.modelResultsTbi)

    }
  
    resultsMap = resultsMap :+ Map((paramsArr.arrayId, paramsModel.modelPheno, paramsModel.modelTest, paramsModel.modelCovars, paramsModel.modelTrans) -> paramsModel.modelResultsCloud)

  }

  return resultsMap.flatten.toMap

}

def qc3(i: Int): Map[(String, String, String, String, String, String), Store] = {

  val (_, paramsArr) = Params.paramsByArr(i)
  var knownLociMap = Seq[Map[(String, String, String, String, String, String), Store]]()

  for {
    (model, paramsKnownLoci) <- paramsArr.paramsByArrByKnownLoci
  } {
  
    google {

      hail"""$pyHailListSamples
        --vds-in ${paramsArr.cleanVdsCloud}
        --bim-in ${paramsArr.harmRefFiltPrunedNameCloud}.bim
        --pheno-in ${Input.Google.pheno}
        --iid-col $phenoId
        --pheno-col ${paramsKnownLoci.knownLociPhenoName}
        --test ${paramsKnownLoci.knownLociTest}
        --covars "${paramsKnownLoci.knownLociCovars}"
        --out-pheno-prelim ${paramsKnownLoci.knownLociPhenoPrelimFileCloud}
        --out-samples ${paramsKnownLoci.knownLociSamplesIncludeCloud}"""
      .in(paramsArr.harmRefFiltPrunedCloud :+ paramsArr.cleanVdsCloud :+ Input.Google.pheno)
      .out(paramsKnownLoci.knownLociPhenoPrelimFileCloud, paramsKnownLoci.knownLociSamplesIncludeCloud)

    }
    
    local {

      googleCopy(paramsKnownLoci.knownLociPhenoPrelimFileCloud, paramsKnownLoci.knownLociPhenoPrelimFile)
      googleCopy(paramsKnownLoci.knownLociSamplesIncludeCloud, paramsKnownLoci.knownLociSamplesInclude)

    }
    
    uger {

      cmd"""$binRscript --vanilla --verbose
        $rGeneratePheno
        --gds-in ${paramsArr.harmRefFiltPrunedPcaGds}
        --pheno-in ${Input.Local.pheno}
        --ancestry-in ${ancestryInferredMerged}
        --ancestry-keep "${paramsKnownLoci.knownLociPop}"
        --pheno-col ${paramsKnownLoci.knownLociPhenoName}
        --iid-col $phenoId
        --samples-include ${paramsKnownLoci.knownLociSamplesInclude}
        --variants-exclude ID ${paramsArr.finalVariantExclusions}
        --test ${paramsKnownLoci.knownLociTest}
        --trans "${paramsKnownLoci.knownLociTrans}"
        --covars "${paramsKnownLoci.knownLociCovars}"
        --out-pheno ${paramsKnownLoci.knownLociPhenoFile}
        --out-pcs ${paramsKnownLoci.knownLociPcsFile}
        > ${paramsKnownLoci.knownLociPhenoFileLog}"""
        .in(paramsArr.harmRefFiltPrunedPcaGds, Input.Local.pheno, ancestryInferredMerged, paramsKnownLoci.knownLociSamplesInclude, paramsArr.finalVariantExclusions)
        .out(paramsKnownLoci.knownLociPhenoFile, paramsKnownLoci.knownLociPcsFile, paramsKnownLoci.knownLociPhenoFileLog)
        .using("R-3.4")

    }
    
    local {

      googleCopy(paramsKnownLoci.knownLociPhenoFile, paramsKnownLoci.knownLociPhenoFileCloud)
      googleCopy(paramsKnownLoci.knownLociPcsFile, paramsKnownLoci.knownLociPcsFileCloud)
      googleCopy(paramsKnownLoci.knownLociHiLd, paramsKnownLoci.knownLociHiLdCloud)

    }
    
    google {

      hail"""$pyHailAssoc
        --vds-in ${paramsArr.cleanVdsCloud}
        --bim-in ${paramsArr.harmRefFiltPrunedNameCloud}.bim
        --pheno-in ${paramsKnownLoci.knownLociPhenoFileCloud}
        --iid-col $phenoId
        --pheno-col ${paramsKnownLoci.knownLociPhenoName}
        --pcs-include ${paramsKnownLoci.knownLociPcsFileCloud}
        --extract-ld ${paramsKnownLoci.knownLociHiLdCloud}
        --test ${paramsKnownLoci.knownLociTest}
        --trans "${paramsKnownLoci.knownLociTrans}"
        --covars "${paramsKnownLoci.knownLociCovars}"
        --out ${paramsKnownLoci.knownLociResultsCloud}"""
          .in(paramsArr.harmRefFiltPrunedCloud :+ paramsArr.cleanVdsCloud :+ Input.Google.pheno :+ paramsKnownLoci.knownLociPhenoFileCloud :+ paramsKnownLoci.knownLociHiLdCloud)
          .out(paramsKnownLoci.knownLociResultsCloud)
    
    }
    
    local {

      googleCopy(paramsKnownLoci.knownLociResultsCloud, paramsKnownLoci.knownLociResults)

    }
    
    knownLociMap = knownLociMap :+ Map((paramsArr.arrayId, paramsKnownLoci.knownLociPhenoName, paramsKnownLoci.knownLociTest, paramsKnownLoci.knownLociCovars, paramsKnownLoci.knownLociTrans, paramsKnownLoci.knownLociPop) -> paramsKnownLoci.knownLociResultsCloud)
  
  }

  return knownLociMap.flatten.toMap

}


def mergeResults(i: Int): Unit = {

  val (_, paramsResult) = Params.paramsByResult(i)
  
  /**
   * Merge Step
   *  Description: Run association tests
   *  Requires: Hail
   */
  
  val modelResultsMap = resultsStoresMapsList.flatten.toMap.filterKeys({e => e._2 == paramsResult.resultPheno && e._3 == paramsResult.resultTest && e._4 == paramsResult.resultCovars && e._5 == paramsResult.resultTrans})
  
  val modelResultsString = modelResultsMap.map { case (key, value) => s"""${key._1}___${value.toString.split("@")(1)}""" }.mkString(",")

  var reportAnalysisResultKnownLociHiLdList = Seq[Store]()
  var reportAnalysisResultKnownLociHiLdStrings = Seq[String]()
      

  for {
    m <-  knownLociSeq.zipWithIndex.filter(_._1._1 == paramsResult.resultPheno).map(_._2)
  } {
      
    val paramsResultKnownLoci = Params.paramsByResultKnownLociSorted(m)
    reportAnalysisResultKnownLociHiLdList = reportAnalysisResultKnownLociHiLdList :+ paramsResultKnownLoci.resultKnownLociHiLd
    reportAnalysisResultKnownLociHiLdStrings = reportAnalysisResultKnownLociHiLdStrings :+ s"${paramsResultKnownLoci.resultKnownLociHiLd.toString.split("@")(1)}"

  }

  google {

    hail"""$pyHailMerge
      --results "${modelResultsString}"
      --test ${paramsResult.resultTest}
      --out ${paramsResult.resultFinalCloud}
      """.in(modelResultsMap.values).out(paramsResult.resultFinalCloud)

  }
  
  local {

    googleCopy(paramsResult.resultFinalCloud, paramsResult.resultFinal)

  }

  uger {

    cmd"""$binTabix -b 2 -e 2 ${paramsResult.resultFinal}"""
      .in(paramsResult.resultFinal)
      .out(paramsResult.resultFinalTbi)

  }
  
  /**
   * Top Results Step
   *  Description: Extract top results and annotate
   *  Requires: Python
   */
  
  uger {
  
    cmd"""python $pyTop1000
      --results ${paramsResult.resultFinal}
      --p pval 
      --out ${paramsResult.resultFinalTop1000}"""
      .in(paramsResult.resultFinal)
      .out(paramsResult.resultFinalTop1000)
    
    cmd"""(sed '1d' ${paramsResult.resultFinalTop1000} | awk '{print $$1"\t"$$2}' | python $pyAddGeneAnnot --outside-name NA --chr-col 1 --pos-col 2 --gene-file ${Input.Local.genes} --out-delim \\t) | sort -u > ${paramsResult.resultFinalTop1000Genes}"""
      .in(paramsResult.resultFinalTop1000, Input.Local.genes)
      .out(paramsResult.resultFinalTop1000Genes)
    
    cmd"""$binRscript --vanilla --verbose
      $rTop20
      --results ${paramsResult.resultFinalTop1000}
      --chr "#chr"
      --pos pos
      --genes ${paramsResult.resultFinalTop1000Genes}
      --known-loci ${reportAnalysisResultKnownLociHiLdStrings.mkString(",")}
      --p pval
      --test ${paramsResult.resultTest}
      --out ${paramsResult.resultFinalTop20AnnotAlignedRisk}"""
      .in(reportAnalysisResultKnownLociHiLdList :+ paramsResult.resultFinalTop1000 :+ paramsResult.resultFinalTop1000Genes)
      .out(paramsResult.resultFinalTop20AnnotAlignedRisk)
      .using("R-3.4")
  
  }

  /**
   * Plot Step
   *  Description: Run association tests
   *  Requires: Python
   */
  
  uger {

    cmd"""python $pyQqPlot
      --results ${paramsResult.resultFinal}
      --p pval
      --out ${paramsResult.resultFinalQqPlot}
      """.in(paramsResult.resultFinal).out(paramsResult.resultFinalQqPlot)
    
    cmd"""python $pyMhtPlot
      --results ${paramsResult.resultFinal}
      --chr "#chr"
      --pos pos
      --p pval
      --out ${paramsResult.resultFinalMhtPlot}
      """.in(paramsResult.resultFinal).out(paramsResult.resultFinalMhtPlot)
    
    cmd"""python $pyExtractTopRegions
      --results ${paramsResult.resultFinal}
      --chr "#chr"
      --pos pos
      --p pval
      --out ${paramsResult.resultFinalSigRegions}
      """.in(paramsResult.resultFinal).out(paramsResult.resultFinalSigRegions)

  }
  
}

def mergeKnownLoci(i: Int): Unit = {

  val (_, paramsResultKnownLoci) = Params.paramsByResultKnownLoci(i)
  
  /**
   * Merge Step
   *  Description: Run association tests for known loci
   *  Requires: Hail
   */

  val knownLociMap = resultsKnownLociStoresMapsList.flatten.toMap.filterKeys({e => e._2 == paramsResultKnownLoci.resultKnownLociPhenoName && e._3 == paramsResultKnownLoci.resultKnownLociTest && e._4 == paramsResultKnownLoci.resultKnownLociCovars && e._5 == paramsResultKnownLoci.resultKnownLociTrans && e._6 == paramsResultKnownLoci.resultKnownLociPop})
  
  val knownLociString = knownLociMap.map { case (key, value) => s"""${key._1}___${value.toString.split("@")(1)}""" }.mkString(",")

  google {

    hail"""$pyHailMerge
      --results "${knownLociString}"
      --test ${paramsResultKnownLoci.resultKnownLociTest}
      --out ${paramsResultKnownLoci.resultKnownLociFinalCloud}
      """.in(knownLociMap.values).out(paramsResultKnownLoci.resultKnownLociFinalCloud)

  }
  
  local {

    googleCopy(paramsResultKnownLoci.resultKnownLociFinalCloud, paramsResultKnownLoci.resultKnownLociFinal)

  }
  
  uger {

    cmd"""$binRscript --vanilla --verbose
      $rTop50Known
      --results ${paramsResultKnownLoci.resultKnownLociFinal}
      --known-loci ${paramsResultKnownLoci.resultKnownLociData}
      --known-ld ${paramsResultKnownLoci.resultKnownLociHiLd}
      --known-loci-n "${paramsResultKnownLoci.resultKnownLociN}"
      --known-loci-case "${paramsResultKnownLoci.resultKnownLociCase}"
      --known-loci-ctrl "${paramsResultKnownLoci.resultKnownLociCtrl}"
      --test ${paramsResultKnownLoci.resultKnownLociTest}
      --out ${paramsResultKnownLoci.resultKnownLociFinalTop50Known}"""
      .in(paramsResultKnownLoci.resultKnownLociFinal, paramsResultKnownLoci.resultKnownLociData)
      .out(paramsResultKnownLoci.resultKnownLociFinalTop50Known)
      .using("R-3.4")

  }

}

def plotSigRegions(i: Int): Seq[Store] = {

  val (_, paramsResult) = Params.paramsByResult(i)
  var resultsFinalRegplotList = Seq[Store]()
  val regions: Seq[String] = {
    enclosed(scala.io.Source.fromFile(paramsResult.resultFinalSigRegions.path.toFile)) { 
      _.getLines.filter(_.trim.nonEmpty).toIndexedSeq
    }
  }

  for (region <- regions) {
  
    val regionChr = region.split("\t")(0)
    val regionStart = region.split("\t")(1)
    val regionEnd = region.split("\t")(2)
    val regionVar = region.split("\t")(3)
    val resultsFinalRegplotData = store.at(localOutDir / s"${paramsResult.resultFinalRegplotBase}_${regionVar}_chr${regionChr}_${regionStart}_${regionEnd}.data.tsv")
    val resultsFinalRegplotLog = store.at(localOutDir / s"${paramsResult.resultFinalRegplotBase}_${regionVar}_chr${regionChr}_${regionStart}_${regionEnd}.locuszoom.log")
    val resultsFinalRegplotPdf = store.at(localOutDir / s"${paramsResult.resultFinalRegplotBase}_${regionVar}_chr${regionChr}_${regionStart}-${regionEnd}" / s"chr${regionChr}_${regionStart}-${regionEnd}.pdf")
    val resultsFinalRegplotPng = store.at(localOutDir / s"${paramsResult.resultFinalRegplotBase}_${regionVar}_chr${regionChr}_${regionStart}_${regionEnd}.png")

    uger {

      cmd"""pcol=`$binTabix -H ${paramsResult.resultFinal} | tr "\t" "\n" | grep -n pval | awk -F':' '{print $$1}'`; (echo -e "id\tpval"; $binTabix ${paramsResult.resultFinal} ${regionChr}:${regionStart}-${regionEnd} | awk -v pcol=$$pcol '{if(substr($$4 ,0, 2) != "rs") { print "chr"$$1":"$$2"\t"$$pcol } else print $$4"\t"$$pcol}') > ${resultsFinalRegplotData}"""
        .in(paramsResult.resultFinal)
        .out(resultsFinalRegplotData)
      
      cmd"""$binLocuszoom --metal ${resultsFinalRegplotData} --chr $regionChr --start $regionStart --end $regionEnd --markercol id --pvalcol pval --pop EUR --build hg19 --source 1000G_Nov2014 --no-date --prefix ${paramsResult.resultFinalRegplotName}_${regionVar} --cache None  > ${resultsFinalRegplotLog}"""
        .in(resultsFinalRegplotData)
        .out(resultsFinalRegplotPdf, resultsFinalRegplotLog)
      
      cmd"""$binConvert -density 300 -depth 8 -quality 100 -flatten ${resultsFinalRegplotPdf}[0] $resultsFinalRegplotPng"""
        .in(resultsFinalRegplotPdf)
        .out(resultsFinalRegplotPng)

    }
  
    resultsFinalRegplotList = resultsFinalRegplotList :+ resultsFinalRegplotPng
  
  }

  resultsFinalRegplotList

}

